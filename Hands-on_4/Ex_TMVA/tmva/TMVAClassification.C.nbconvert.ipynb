{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca276629",
   "metadata": {},
   "source": [
    "# TMVAClassification\n",
    "This macro provides examples for the training and testing of the\n",
    "TMVA classifiers.\n",
    "\n",
    "As input data is used a toy-MC sample consisting of four Gaussian-distributed\n",
    "and linearly correlated input variables.\n",
    "The methods to be used can be switched on and off by means of booleans, or\n",
    "via the prompt command, for example:\n",
    "\n",
    "    root -l ./TMVAClassification.C\\(\\\"Fisher,Likelihood\\\"\\)\n",
    "\n",
    "(note that the backslashes are mandatory)\n",
    "If no method given, a default set of classifiers is used.\n",
    "The output file \"TMVAC.root\" can be analysed with the use of dedicated\n",
    "macros (simply say: root -l <macro.C>), which can be conveniently\n",
    "invoked through a GUI that will appear at the end of the run of this macro.\n",
    "Launch the GUI via the command:\n",
    "\n",
    "    root -l ./TMVAGui.C\n",
    "\n",
    "You can also compile and run the example with the following commands\n",
    "\n",
    "    make\n",
    "    ./TMVAClassification <Methods>\n",
    "\n",
    "where: `<Methods> = \"method1 method2\"` are the TMVA classifier names\n",
    "example:\n",
    "\n",
    "    ./TMVAClassification Fisher LikelihoodPCA BDT\n",
    "\n",
    "If no method given, a default set is of classifiers is used\n",
    "\n",
    "- Project   : TMVA - a ROOT-integrated toolkit for multivariate data analysis\n",
    "- Package   : TMVA\n",
    "- Root Macro: TMVAClassification\n",
    "\n",
    "\n",
    "\n",
    "**Author:** Andreas Hoecker  \n",
    "<i><small>This notebook tutorial was automatically generated with <a href= \"https://github.com/root-project/root/blob/master/documentation/doxygen/converttonotebook.py\">ROOTBOOK-izer</a> from the macro found in the ROOT repository  on Friday, December 13, 2024 at 10:17 AM.</small></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4344ad41",
   "metadata": {},
   "source": [
    " Arguments are defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4e3794",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:52.051746Z",
     "iopub.status.busy": "2024-12-13T10:17:52.051365Z",
     "iopub.status.idle": "2024-12-13T10:17:52.920058Z",
     "shell.execute_reply": "2024-12-13T10:17:52.919077Z"
    }
   },
   "outputs": [],
   "source": [
    "TString myMethodList = \"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce6c96",
   "metadata": {},
   "source": [
    "The explicit loading of the shared libTMVA is done in TMVAlogon.C, defined in .rootrc\n",
    "if you use your private .rootrc, or run from a different directory, please copy the\n",
    "corresponding lines from .rootrc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ea9b5",
   "metadata": {},
   "source": [
    "Methods to be processed can be given as an argument; use format:\n",
    "\n",
    "mylinux~> root -l TMVAClassification.C\\(\\\"myMethod1,myMethod2,myMethod3\\\"\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f1bb8",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------\n",
    "This loads the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a998cfbc",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:52.925080Z",
     "iopub.status.busy": "2024-12-13T10:17:52.924797Z",
     "iopub.status.idle": "2024-12-13T10:17:53.248187Z",
     "shell.execute_reply": "2024-12-13T10:17:53.247213Z"
    }
   },
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be79d14",
   "metadata": {},
   "source": [
    "Default MVA methods to be trained + tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9551017",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:53.252604Z",
     "iopub.status.busy": "2024-12-13T10:17:53.252322Z",
     "iopub.status.idle": "2024-12-13T10:17:53.464165Z",
     "shell.execute_reply": "2024-12-13T10:17:53.463201Z"
    }
   },
   "outputs": [],
   "source": [
    "std::map<std::string,int> Use;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0020082",
   "metadata": {},
   "source": [
    "Cut optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1050c265",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:53.468590Z",
     "iopub.status.busy": "2024-12-13T10:17:53.468313Z",
     "iopub.status.idle": "2024-12-13T10:17:54.089184Z",
     "shell.execute_reply": "2024-12-13T10:17:54.088254Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"Cuts\"]            = 1;\n",
    "Use[\"CutsD\"]           = 1;\n",
    "Use[\"CutsPCA\"]         = 0;\n",
    "Use[\"CutsGA\"]          = 0;\n",
    "Use[\"CutsSA\"]          = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafa5d3",
   "metadata": {},
   "source": [
    "1-dimensional likelihood (\"naive Bayes estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03243fbc",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:54.093616Z",
     "iopub.status.busy": "2024-12-13T10:17:54.093332Z",
     "iopub.status.idle": "2024-12-13T10:17:54.459979Z",
     "shell.execute_reply": "2024-12-13T10:17:54.458896Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"Likelihood\"]      = 1;\n",
    "Use[\"LikelihoodD\"]     = 0; // the \"D\" extension indicates decorrelated input variables (see option strings)\n",
    "Use[\"LikelihoodPCA\"]   = 1; // the \"PCA\" extension indicates PCA-transformed input variables (see option strings)\n",
    "Use[\"LikelihoodKDE\"]   = 0;\n",
    "Use[\"LikelihoodMIX\"]   = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84f8e0",
   "metadata": {},
   "source": [
    "Mutidimensional likelihood and Nearest-Neighbour methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97aa721",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:54.464495Z",
     "iopub.status.busy": "2024-12-13T10:17:54.464210Z",
     "iopub.status.idle": "2024-12-13T10:17:54.672272Z",
     "shell.execute_reply": "2024-12-13T10:17:54.671288Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"PDERS\"]           = 1;\n",
    "Use[\"PDERSD\"]          = 0;\n",
    "Use[\"PDERSPCA\"]        = 0;\n",
    "Use[\"PDEFoam\"]         = 1;\n",
    "Use[\"PDEFoamBoost\"]    = 0; // uses generalised MVA method boosting\n",
    "Use[\"KNN\"]             = 1; // k-nearest neighbour method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658e56c",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9275d525",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:54.676631Z",
     "iopub.status.busy": "2024-12-13T10:17:54.676348Z",
     "iopub.status.idle": "2024-12-13T10:17:54.888146Z",
     "shell.execute_reply": "2024-12-13T10:17:54.887150Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"LD\"]              = 1; // Linear Discriminant identical to Fisher\n",
    "Use[\"Fisher\"]          = 0;\n",
    "Use[\"FisherG\"]         = 0;\n",
    "Use[\"BoostedFisher\"]   = 0; // uses generalised MVA method boosting\n",
    "Use[\"HMatrix\"]         = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192bf3ce",
   "metadata": {},
   "source": [
    "Function Discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d5ffff",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:54.892498Z",
     "iopub.status.busy": "2024-12-13T10:17:54.892219Z",
     "iopub.status.idle": "2024-12-13T10:17:55.105479Z",
     "shell.execute_reply": "2024-12-13T10:17:55.103763Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"FDA_GA\"]          = 1; // minimisation of user-defined function using Genetics Algorithm\n",
    "Use[\"FDA_SA\"]          = 0;\n",
    "Use[\"FDA_MC\"]          = 0;\n",
    "Use[\"FDA_MT\"]          = 0;\n",
    "Use[\"FDA_GAMT\"]        = 0;\n",
    "Use[\"FDA_MCMT\"]        = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bf35a",
   "metadata": {},
   "source": [
    "Neural Networks (all are feed-forward Multilayer Perceptrons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c07ab8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:55.109794Z",
     "iopub.status.busy": "2024-12-13T10:17:55.109502Z",
     "iopub.status.idle": "2024-12-13T10:17:55.328089Z",
     "shell.execute_reply": "2024-12-13T10:17:55.327067Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"MLP\"]             = 0; // Recommended ANN\n",
    "Use[\"MLPBFGS\"]         = 0; // Recommended ANN with optional training method\n",
    "Use[\"MLPBNN\"]          = 1; // Recommended ANN with BFGS training method and bayesian regulator\n",
    "Use[\"CFMlpANN\"]        = 0; // Depreciated ANN from ALEPH\n",
    "Use[\"TMlpANN\"]         = 0; // ROOT's own ANN\n",
    "#ifdef R__HAS_TMVAGPU\n",
    "Use[\"DNN_GPU\"]         = 1; // CUDA-accelerated DNN training.\n",
    "#else\n",
    "Use[\"DNN_GPU\"]         = 0;\n",
    "#endif\n",
    "\n",
    "#ifdef R__HAS_TMVACPU\n",
    "Use[\"DNN_CPU\"]         = 1; // Multi-core accelerated DNN.\n",
    "#else\n",
    "Use[\"DNN_CPU\"]         = 0;\n",
    "#endif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d1e5a",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4390d991",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:55.332475Z",
     "iopub.status.busy": "2024-12-13T10:17:55.332188Z",
     "iopub.status.idle": "2024-12-13T10:17:55.544204Z",
     "shell.execute_reply": "2024-12-13T10:17:55.543199Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"SVM\"]             = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ae3ee",
   "metadata": {},
   "source": [
    "Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddcc73d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:55.548517Z",
     "iopub.status.busy": "2024-12-13T10:17:55.548231Z",
     "iopub.status.idle": "2024-12-13T10:17:55.756316Z",
     "shell.execute_reply": "2024-12-13T10:17:55.755333Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"BDT\"]             = 1; // uses Adaptive Boost\n",
    "Use[\"BDTG\"]            = 0; // uses Gradient Boost\n",
    "Use[\"BDTB\"]            = 0; // uses Bagging\n",
    "Use[\"BDTD\"]            = 0; // decorrelation + Adaptive Boost\n",
    "Use[\"BDTF\"]            = 0; // allow usage of fisher discriminant for node splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01396c",
   "metadata": {},
   "source": [
    "Friedman's RuleFit method, ie, an optimised series of cuts (\"rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df8c9f9",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:55.760729Z",
     "iopub.status.busy": "2024-12-13T10:17:55.760428Z",
     "iopub.status.idle": "2024-12-13T10:17:55.972421Z",
     "shell.execute_reply": "2024-12-13T10:17:55.971448Z"
    }
   },
   "outputs": [],
   "source": [
    "Use[\"RuleFit\"]         = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357bc2ca",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c837c7",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:55.976739Z",
     "iopub.status.busy": "2024-12-13T10:17:55.976440Z",
     "iopub.status.idle": "2024-12-13T10:17:56.188632Z",
     "shell.execute_reply": "2024-12-13T10:17:56.187775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Start TMVAClassification\n"
     ]
    }
   ],
   "source": [
    "std::cout << std::endl;\n",
    "std::cout << \"==> Start TMVAClassification\" << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5a73e",
   "metadata": {},
   "source": [
    "Select methods (don't look at this code - not of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58c829e",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:56.192635Z",
     "iopub.status.busy": "2024-12-13T10:17:56.192348Z",
     "iopub.status.idle": "2024-12-13T10:17:56.949017Z",
     "shell.execute_reply": "2024-12-13T10:17:56.948075Z"
    }
   },
   "outputs": [],
   "source": [
    "if (myMethodList != \"\") {\n",
    "   for (std::map<std::string,int>::iterator it = Use.begin(); it != Use.end(); it++) it->second = 0;\n",
    "\n",
    "   std::vector<TString> mlist = TMVA::gTools().SplitString( myMethodList, ',' );\n",
    "   for (UInt_t i=0; i<mlist.size(); i++) {\n",
    "      std::string regMethod(mlist[i]);\n",
    "\n",
    "      if (Use.find(regMethod) == Use.end()) {\n",
    "         std::cout << \"Method \\\"\" << regMethod << \"\\\" not known in TMVA under this name. Choose among the following:\" << std::endl;\n",
    "         for (std::map<std::string,int>::iterator it = Use.begin(); it != Use.end(); it++) std::cout << it->first << \" \";\n",
    "         std::cout << std::endl;\n",
    "         return 1;\n",
    "      }\n",
    "      Use[regMethod] = 1;\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c43761",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936da841",
   "metadata": {},
   "source": [
    "Here the preparation phase begins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d19896",
   "metadata": {},
   "source": [
    "Read training and test data\n",
    "(it is also possible to use ASCII format as input -> see TMVA Users Guide)\n",
    "Set the cache directory for the TFile to the current directory. The input\n",
    "data file will be downloaded here if not present yet, then it will be read\n",
    "from the cache path directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "001cc0e4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:56.953555Z",
     "iopub.status.busy": "2024-12-13T10:17:56.953270Z",
     "iopub.status.idle": "2024-12-13T10:17:57.501313Z",
     "shell.execute_reply": "2024-12-13T10:17:57.500438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TMVAClassification       : Using input file: ./files/tmva_class_example.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TFile::OpenFromCache>: using local cache copy of http://root.cern/files/tmva_class_example.root [./files/tmva_class_example.root]\n"
     ]
    }
   ],
   "source": [
    "TFile::SetCacheFileDir(\".\");\n",
    "std::unique_ptr<TFile> input{TFile::Open(\"http://root.cern/files/tmva_class_example.root\", \"CACHEREAD\")};\n",
    "if (!input || input->IsZombie()) {\n",
    "   throw std::runtime_error(\"ERROR: could not open data file\");\n",
    "}\n",
    "std::cout << \"--- TMVAClassification       : Using input file: \" << input->GetName() << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70182545",
   "metadata": {},
   "source": [
    "Register the training and test trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2dd3506",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:57.505542Z",
     "iopub.status.busy": "2024-12-13T10:17:57.505259Z",
     "iopub.status.idle": "2024-12-13T10:17:57.713211Z",
     "shell.execute_reply": "2024-12-13T10:17:57.712276Z"
    }
   },
   "outputs": [],
   "source": [
    "TTree *signalTree     = (TTree*)input->Get(\"TreeS\");\n",
    "TTree *background     = (TTree*)input->Get(\"TreeB\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20451abf",
   "metadata": {},
   "source": [
    "Create a ROOT output file where TMVA will store ntuples, histograms, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff2bb7cc",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:57.717496Z",
     "iopub.status.busy": "2024-12-13T10:17:57.717211Z",
     "iopub.status.idle": "2024-12-13T10:17:57.921029Z",
     "shell.execute_reply": "2024-12-13T10:17:57.920052Z"
    }
   },
   "outputs": [],
   "source": [
    "TString outfileName(\"TMVAC.root\");\n",
    "std::unique_ptr<TFile> outputFile{TFile::Open(outfileName, \"RECREATE\")};\n",
    "if (!outputFile || outputFile->IsZombie()) {\n",
    "   throw std::runtime_error(\"ERROR: could not open output file\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef071efc",
   "metadata": {},
   "source": [
    "Create the factory object. Later you can choose the methods\n",
    "whose performance you'd like to investigate. The factory is\n",
    "the only TMVA object you have to interact with\n",
    "\n",
    "The first argument is the base of the name of all the\n",
    "weightfiles in the directory weight\n",
    "\n",
    "The second argument is the output file for the training results\n",
    "All TMVA output can be suppressed by removing the \"!\" (not) in\n",
    "front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ade3fc6c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:57.925266Z",
     "iopub.status.busy": "2024-12-13T10:17:57.924985Z",
     "iopub.status.idle": "2024-12-13T10:17:58.609294Z",
     "shell.execute_reply": "2024-12-13T10:17:58.608305Z"
    }
   },
   "outputs": [],
   "source": [
    "auto factory = std::make_unique<TMVA::Factory>(\n",
    "   \"TMVAClassification\", outputFile.get(),\n",
    "   \"!V:!Silent:Color:!DrawProgressBar:Transformations=I;D;P;G,D:AnalysisType=Classification\");\n",
    "auto dataloader_raii = std::make_unique<TMVA::DataLoader>(\"dataset\");\n",
    "auto *dataloader = dataloader_raii.get();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa1a64",
   "metadata": {},
   "source": [
    "If you wish to modify default settings\n",
    "(please check \"src/Config.h\" to see all available global options)\n",
    "\n",
    "(TMVA::gConfig().GetVariablePlotting()).fTimesRMS = 8.0;\n",
    "(TMVA::gConfig().GetIONames()).fWeightFileDir = \"myWeightDirectory\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26da66",
   "metadata": {},
   "source": [
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, such as: \"3*var1/var2*abs(var3)\"\n",
    "[all types of expressions that can also be parsed by TTree::Draw( \"expression\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32cc41e4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:58.613857Z",
     "iopub.status.busy": "2024-12-13T10:17:58.613562Z",
     "iopub.status.idle": "2024-12-13T10:17:58.818911Z",
     "shell.execute_reply": "2024-12-13T10:17:58.817942Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader->AddVariable( \"myvar1 := var1+var2\", 'F' );\n",
    "dataloader->AddVariable( \"myvar2 := var1-var2\", \"Expression 2\", \"\", 'F' );\n",
    "dataloader->AddVariable( \"var3\",                \"Variable 3\", \"units\", 'F' );\n",
    "dataloader->AddVariable( \"var4\",                \"Variable 4\", \"units\", 'F' );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f658b3",
   "metadata": {},
   "source": [
    "You can add so-called \"Spectator variables\", which are not used in the MVA training,\n",
    "but will appear in the final \"TestTree\" produced by TMVA. This TestTree will contain the\n",
    "input variables, the response values of all trained MVAs, and the spectator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09218b5e",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:58.823144Z",
     "iopub.status.busy": "2024-12-13T10:17:58.822840Z",
     "iopub.status.idle": "2024-12-13T10:17:59.026581Z",
     "shell.execute_reply": "2024-12-13T10:17:59.025648Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader->AddSpectator( \"spec1 := var1*2\",  \"Spectator 1\", \"units\", 'F' );\n",
    "dataloader->AddSpectator( \"spec2 := var1*3\",  \"Spectator 2\", \"units\", 'F' );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d421b",
   "metadata": {},
   "source": [
    "global event weights per tree (see below for setting event-wise weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82398fc9",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:59.030917Z",
     "iopub.status.busy": "2024-12-13T10:17:59.030604Z",
     "iopub.status.idle": "2024-12-13T10:17:59.245398Z",
     "shell.execute_reply": "2024-12-13T10:17:59.244443Z"
    }
   },
   "outputs": [],
   "source": [
    "Double_t signalWeight     = 1.0;\n",
    "Double_t backgroundWeight = 1.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54a6d3",
   "metadata": {},
   "source": [
    "You can add an arbitrary number of signal or background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09c95c7a",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:59.249789Z",
     "iopub.status.busy": "2024-12-13T10:17:59.249493Z",
     "iopub.status.idle": "2024-12-13T10:17:59.458139Z",
     "shell.execute_reply": "2024-12-13T10:17:59.457275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree TreeS of type Signal with 6000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree TreeB of type Background with 6000 events\n"
     ]
    }
   ],
   "source": [
    "dataloader->AddSignalTree    ( signalTree,     signalWeight );\n",
    "dataloader->AddBackgroundTree( background, backgroundWeight );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c58",
   "metadata": {},
   "source": [
    "To give different trees for training and testing, do as follows:\n",
    "\n",
    "dataloader->AddSignalTree( signalTrainingTree, signalTrainWeight, \"Training\" );\n",
    "dataloader->AddSignalTree( signalTestTree,     signalTestWeight,  \"Test\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb6224",
   "metadata": {},
   "source": [
    "Use the following code instead of the above two or four lines to add signal and background\n",
    "training and test events \"by hand\"\n",
    "NOTE that in this case one should not give expressions (such as \"var1+var2\") in the input\n",
    "variable definition, but simply compute the expression before adding the event\n",
    "```cpp\n",
    "--- begin ----------------------------------------------------------\n",
    "std::vector<Double_t> vars( 4 ); // vector has size of number of input variables\n",
    "Float_t  treevars[4], weight;\n",
    "\n",
    "Signal\n",
    "for (UInt_t ivar=0; ivar<4; ivar++) signalTree->SetBranchAddress( Form( \"var%i\", ivar+1 ), &(treevars[ivar]) );\n",
    "for (UInt_t i=0; i<signalTree->GetEntries(); i++) {\n",
    "signalTree->GetEntry(i);\n",
    "for (UInt_t ivar=0; ivar<4; ivar++) vars[ivar] = treevars[ivar];\n",
    "add training and test events; here: first half is training, second is testing\n",
    "note that the weight can also be event-wise\n",
    "if (i < signalTree->GetEntries()/2.0) dataloader->AddSignalTrainingEvent( vars, signalWeight );\n",
    "else                              dataloader->AddSignalTestEvent    ( vars, signalWeight );\n",
    "}\n",
    "\n",
    "Background (has event weights)\n",
    "background->SetBranchAddress( \"weight\", &weight );\n",
    "for (UInt_t ivar=0; ivar<4; ivar++) background->SetBranchAddress( Form( \"var%i\", ivar+1 ), &(treevars[ivar]) );\n",
    "for (UInt_t i=0; i<background->GetEntries(); i++) {\n",
    "background->GetEntry(i);\n",
    "for (UInt_t ivar=0; ivar<4; ivar++) vars[ivar] = treevars[ivar];\n",
    "add training and test events; here: first half is training, second is testing\n",
    "note that the weight can also be event-wise\n",
    "if (i < background->GetEntries()/2) dataloader->AddBackgroundTrainingEvent( vars, backgroundWeight*weight );\n",
    "else                                dataloader->AddBackgroundTestEvent    ( vars, backgroundWeight*weight );\n",
    "}\n",
    "--- end ------------------------------------------------------------\n",
    "```\n",
    "End of tree registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639254f3",
   "metadata": {},
   "source": [
    "Set individual event weights (the variables must exist in the original TTree)\n",
    "-  for signal    : `dataloader->SetSignalWeightExpression    (\"weight1*weight2\");`\n",
    "-  for background: `dataloader->SetBackgroundWeightExpression(\"weight1*weight2\");`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fe73279",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:59.462014Z",
     "iopub.status.busy": "2024-12-13T10:17:59.461730Z",
     "iopub.status.idle": "2024-12-13T10:17:59.665377Z",
     "shell.execute_reply": "2024-12-13T10:17:59.664456Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader->SetBackgroundWeightExpression( \"weight\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b74c7",
   "metadata": {},
   "source": [
    "Apply additional cuts on the signal and background samples (can be different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37799c7a",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:59.669726Z",
     "iopub.status.busy": "2024-12-13T10:17:59.669426Z",
     "iopub.status.idle": "2024-12-13T10:17:59.931794Z",
     "shell.execute_reply": "2024-12-13T10:17:59.930793Z"
    }
   },
   "outputs": [],
   "source": [
    "TCut mycuts = \"\"; // for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "TCut mycutb = \"\"; // for example: TCut mycutb = \"abs(var1)<0.5\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99721aa1",
   "metadata": {},
   "source": [
    "Tell the dataloader how to use the training and testing events\n",
    "\n",
    "If no numbers of events are given, half of the events in the tree are used\n",
    "for training, and the other half for testing:\n",
    "\n",
    "dataloader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "\n",
    "To also specify the number of testing events, use:\n",
    "\n",
    "dataloader->PrepareTrainingAndTestTree( mycut,\n",
    "\"NSigTrain=3000:NBkgTrain=3000:NSigTest=3000:NBkgTest=3000:SplitMode=Random:!V\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b928e09b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:17:59.943073Z",
     "iopub.status.busy": "2024-12-13T10:17:59.942701Z",
     "iopub.status.idle": "2024-12-13T10:18:00.146629Z",
     "shell.execute_reply": "2024-12-13T10:18:00.145687Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader->PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                     \"nTrain_Signal=1000:nTrain_Background=1000:SplitMode=Random:NormMode=NumEvents:!V\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662fa23",
   "metadata": {},
   "source": [
    "### Book MVA methods\n",
    "\n",
    "Please lookup the various method configuration options in the corresponding cxx files, eg:\n",
    "src/MethoCuts.cxx, etc, or here: http://tmva.sourceforge.net/old_site/optionRef.html\n",
    "it is possible to preset ranges in the option string in which the cut optimisation should be done:\n",
    "\"...:CutRangeMin[2]=-1:CutRangeMax[2]=1\"...\", where [2] is the third input variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bc03f",
   "metadata": {},
   "source": [
    "Cut optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "618a97c1",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:00.151190Z",
     "iopub.status.busy": "2024-12-13T10:18:00.150902Z",
     "iopub.status.idle": "2024-12-13T10:18:00.471938Z",
     "shell.execute_reply": "2024-12-13T10:18:00.471026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mCuts\u001b[0m\n",
      "                         : \n",
      "                         : Use optimization method: \"Monte Carlo\"\n",
      "                         : Use efficiency computation method: \"Event Selection\"\n",
      "                         : Use \"FSmart\" cuts for variable: 'myvar1'\n",
      "                         : Use \"FSmart\" cuts for variable: 'myvar2'\n",
      "                         : Use \"FSmart\" cuts for variable: 'var3'\n",
      "                         : Use \"FSmart\" cuts for variable: 'var4'\n",
      "Factory                  : Booking method: \u001b[1mCutsD\u001b[0m\n",
      "                         : \n",
      "CutsD                    : [dataset] : Create Transformation \"Decorrelate\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Use optimization method: \"Monte Carlo\"\n",
      "                         : Use efficiency computation method: \"Event Selection\"\n",
      "                         : Use \"FSmart\" cuts for variable: 'myvar1'\n",
      "                         : Use \"FSmart\" cuts for variable: 'myvar2'\n",
      "                         : Use \"FSmart\" cuts for variable: 'var3'\n",
      "                         : Use \"FSmart\" cuts for variable: 'var4'\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"Cuts\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kCuts, \"Cuts\",\n",
    "                        \"!H:!V:FitMethod=MC:EffSel:SampleSize=200000:VarProp=FSmart\" );\n",
    "\n",
    "if (Use[\"CutsD\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kCuts, \"CutsD\",\n",
    "                        \"!H:!V:FitMethod=MC:EffSel:SampleSize=200000:VarProp=FSmart:VarTransform=Decorrelate\" );\n",
    "\n",
    "if (Use[\"CutsPCA\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kCuts, \"CutsPCA\",\n",
    "                        \"!H:!V:FitMethod=MC:EffSel:SampleSize=200000:VarProp=FSmart:VarTransform=PCA\" );\n",
    "\n",
    "if (Use[\"CutsGA\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kCuts, \"CutsGA\",\n",
    "                        \"H:!V:FitMethod=GA:CutRangeMin[0]=-10:CutRangeMax[0]=10:VarProp[1]=FMax:EffSel:Steps=30:Cycles=3:PopSize=400:SC_steps=10:SC_rate=5:SC_factor=0.95\" );\n",
    "\n",
    "if (Use[\"CutsSA\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kCuts, \"CutsSA\",\n",
    "                        \"!H:!V:FitMethod=SA:EffSel:MaxCalls=150000:KernelTemp=IncAdaptive:InitialTemp=1e+6:MinTemp=1e-6:Eps=1e-10:UseDefaultScale\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c40928",
   "metadata": {},
   "source": [
    "Likelihood (\"naive Bayes estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88312d0c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:00.475583Z",
     "iopub.status.busy": "2024-12-13T10:18:00.475298Z",
     "iopub.status.idle": "2024-12-13T10:18:00.679437Z",
     "shell.execute_reply": "2024-12-13T10:18:00.678566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mLikelihood\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"Likelihood\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kLikelihood, \"Likelihood\",\n",
    "                        \"H:!V:TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmoothBkg[1]=10:NSmooth=1:NAvEvtPerBin=50\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381d0ba",
   "metadata": {},
   "source": [
    "Decorrelated likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a51e136",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:00.683141Z",
     "iopub.status.busy": "2024-12-13T10:18:00.682844Z",
     "iopub.status.idle": "2024-12-13T10:18:00.886699Z",
     "shell.execute_reply": "2024-12-13T10:18:00.885726Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"LikelihoodD\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kLikelihood, \"LikelihoodD\",\n",
    "                        \"!H:!V:TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmooth=5:NAvEvtPerBin=50:VarTransform=Decorrelate\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4424c",
   "metadata": {},
   "source": [
    "PCA-transformed likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45057649",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:00.891173Z",
     "iopub.status.busy": "2024-12-13T10:18:00.890874Z",
     "iopub.status.idle": "2024-12-13T10:18:01.095569Z",
     "shell.execute_reply": "2024-12-13T10:18:01.094697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mLikelihoodPCA\u001b[0m\n",
      "                         : \n",
      "LikelihoodPCA            : [dataset] : Create Transformation \"PCA\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"LikelihoodPCA\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kLikelihood, \"LikelihoodPCA\",\n",
    "                        \"!H:!V:!TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmooth=5:NAvEvtPerBin=50:VarTransform=PCA\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65244bb5",
   "metadata": {},
   "source": [
    "Use a kernel density estimator to approximate the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18b66ed6",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:01.099268Z",
     "iopub.status.busy": "2024-12-13T10:18:01.098984Z",
     "iopub.status.idle": "2024-12-13T10:18:01.302779Z",
     "shell.execute_reply": "2024-12-13T10:18:01.301804Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"LikelihoodKDE\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kLikelihood, \"LikelihoodKDE\",\n",
    "                        \"!H:!V:!TransformOutput:PDFInterpol=KDE:KDEtype=Gauss:KDEiter=Adaptive:KDEFineFactor=0.3:KDEborder=None:NAvEvtPerBin=50\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed55b8",
   "metadata": {},
   "source": [
    "Use a variable-dependent mix of splines and kernel density estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ddc7f62",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:01.307148Z",
     "iopub.status.busy": "2024-12-13T10:18:01.306848Z",
     "iopub.status.idle": "2024-12-13T10:18:01.511275Z",
     "shell.execute_reply": "2024-12-13T10:18:01.510243Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"LikelihoodMIX\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kLikelihood, \"LikelihoodMIX\",\n",
    "                        \"!H:!V:!TransformOutput:PDFInterpolSig[0]=KDE:PDFInterpolBkg[0]=KDE:PDFInterpolSig[1]=KDE:PDFInterpolBkg[1]=KDE:PDFInterpolSig[2]=Spline2:PDFInterpolBkg[2]=Spline2:PDFInterpolSig[3]=Spline2:PDFInterpolBkg[3]=Spline2:KDEtype=Gauss:KDEiter=Nonadaptive:KDEborder=None:NAvEvtPerBin=50\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179f65bc",
   "metadata": {},
   "source": [
    "Test the multi-dimensional probability density estimator\n",
    "here are the options strings for the MinMax and RMS methods, respectively:\n",
    "\n",
    "\"!H:!V:VolumeRangeMode=MinMax:DeltaFrac=0.2:KernelEstimator=Gauss:GaussSigma=0.3\" );\n",
    "\"!H:!V:VolumeRangeMode=RMS:DeltaFrac=3:KernelEstimator=Gauss:GaussSigma=0.3\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "519744dd",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:01.515695Z",
     "iopub.status.busy": "2024-12-13T10:18:01.515391Z",
     "iopub.status.idle": "2024-12-13T10:18:01.719695Z",
     "shell.execute_reply": "2024-12-13T10:18:01.718702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mPDERS\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"PDERS\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kPDERS, \"PDERS\",\n",
    "                        \"!H:!V:NormTree=T:VolumeRangeMode=Adaptive:KernelEstimator=Gauss:GaussSigma=0.3:NEventsMin=400:NEventsMax=600\" );\n",
    "\n",
    "if (Use[\"PDERSD\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kPDERS, \"PDERSD\",\n",
    "                        \"!H:!V:VolumeRangeMode=Adaptive:KernelEstimator=Gauss:GaussSigma=0.3:NEventsMin=400:NEventsMax=600:VarTransform=Decorrelate\" );\n",
    "\n",
    "if (Use[\"PDERSPCA\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kPDERS, \"PDERSPCA\",\n",
    "                        \"!H:!V:VolumeRangeMode=Adaptive:KernelEstimator=Gauss:GaussSigma=0.3:NEventsMin=400:NEventsMax=600:VarTransform=PCA\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e9f074",
   "metadata": {},
   "source": [
    "Multi-dimensional likelihood estimator using self-adapting phase-space binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eb62e18",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:01.723403Z",
     "iopub.status.busy": "2024-12-13T10:18:01.723120Z",
     "iopub.status.idle": "2024-12-13T10:18:01.927704Z",
     "shell.execute_reply": "2024-12-13T10:18:01.926766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mPDEFoam\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"PDEFoam\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kPDEFoam, \"PDEFoam\",\n",
    "                        \"!H:!V:SigBgSeparate=F:TailCut=0.001:VolFrac=0.0666:nActiveCells=500:nSampl=2000:nBin=5:Nmin=100:Kernel=None:Compress=T\" );\n",
    "\n",
    "if (Use[\"PDEFoamBoost\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kPDEFoam, \"PDEFoamBoost\",\n",
    "                        \"!H:!V:Boost_Num=30:Boost_Transform=linear:SigBgSeparate=F:MaxDepth=4:UseYesNoCell=T:DTLogic=MisClassificationError:FillFoamWithOrigWeights=F:TailCut=0:nActiveCells=500:nBin=20:Nmin=400:Kernel=None:Compress=T\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910beb1",
   "metadata": {},
   "source": [
    "K-Nearest Neighbour classifier (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1393ede5",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:01.931470Z",
     "iopub.status.busy": "2024-12-13T10:18:01.931182Z",
     "iopub.status.idle": "2024-12-13T10:18:02.298536Z",
     "shell.execute_reply": "2024-12-13T10:18:02.297667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mKNN\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"KNN\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kKNN, \"KNN\",\n",
    "                        \"H:nkNN=20:ScaleFrac=0.8:SigmaFact=1.0:Kernel=Gaus:UseKernel=F:UseWeight=T:!Trim\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c70185",
   "metadata": {},
   "source": [
    "H-Matrix (chi2-squared) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0459bd88",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:02.302377Z",
     "iopub.status.busy": "2024-12-13T10:18:02.302093Z",
     "iopub.status.idle": "2024-12-13T10:18:02.506529Z",
     "shell.execute_reply": "2024-12-13T10:18:02.505538Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"HMatrix\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kHMatrix, \"HMatrix\", \"!H:!V:VarTransform=None\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f33ece",
   "metadata": {},
   "source": [
    "Linear discriminant (same as Fisher discriminant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80e8912c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:02.511002Z",
     "iopub.status.busy": "2024-12-13T10:18:02.510693Z",
     "iopub.status.idle": "2024-12-13T10:18:02.857267Z",
     "shell.execute_reply": "2024-12-13T10:18:02.856288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mLD\u001b[0m\n",
      "                         : \n",
      "                         : Rebuilding Dataset dataset\n",
      "                         : Building event vectors for type 2 Signal\n",
      "                         : Dataset[dataset] :  create input formulas for tree TreeS\n",
      "                         : Building event vectors for type 2 Background\n",
      "                         : Dataset[dataset] :  create input formulas for tree TreeB\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 1000\n",
      "                         : Signal     -- testing events             : 5000\n",
      "                         : Signal     -- training and testing events: 6000\n",
      "                         : Background -- training events            : 1000\n",
      "                         : Background -- testing events             : 5000\n",
      "                         : Background -- training and testing events: 6000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------\n",
      "                         :           myvar1  myvar2    var3    var4\n",
      "                         :  myvar1:  +1.000  +0.038  +0.748  +0.922\n",
      "                         :  myvar2:  +0.038  +1.000  -0.058  +0.128\n",
      "                         :    var3:  +0.748  -0.058  +1.000  +0.831\n",
      "                         :    var4:  +0.922  +0.128  +0.831  +1.000\n",
      "                         : ----------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------\n",
      "                         :           myvar1  myvar2    var3    var4\n",
      "                         :  myvar1:  +1.000  -0.021  +0.783  +0.931\n",
      "                         :  myvar2:  -0.021  +1.000  -0.162  +0.057\n",
      "                         :    var3:  +0.783  -0.162  +1.000  +0.841\n",
      "                         :    var4:  +0.931  +0.057  +0.841  +1.000\n",
      "                         : ----------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"LD\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kLD, \"LD\", \"H:!V:VarTransform=None:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:NsmoothMVAPdf=10\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb66659",
   "metadata": {},
   "source": [
    "Fisher discriminant (same as LD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fd63228",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:02.861097Z",
     "iopub.status.busy": "2024-12-13T10:18:02.860767Z",
     "iopub.status.idle": "2024-12-13T10:18:03.064856Z",
     "shell.execute_reply": "2024-12-13T10:18:03.063835Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"Fisher\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFisher, \"Fisher\", \"H:!V:Fisher:VarTransform=None:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:NsmoothMVAPdf=10\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a5c85",
   "metadata": {},
   "source": [
    "Fisher with Gauss-transformed input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1947d49",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:03.069201Z",
     "iopub.status.busy": "2024-12-13T10:18:03.068917Z",
     "iopub.status.idle": "2024-12-13T10:18:03.273230Z",
     "shell.execute_reply": "2024-12-13T10:18:03.272076Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"FisherG\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFisher, \"FisherG\", \"H:!V:VarTransform=Gauss\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9c123",
   "metadata": {},
   "source": [
    "Composite classifier: ensemble (tree) of boosted Fisher classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "714b8af4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:03.277534Z",
     "iopub.status.busy": "2024-12-13T10:18:03.277244Z",
     "iopub.status.idle": "2024-12-13T10:18:03.585078Z",
     "shell.execute_reply": "2024-12-13T10:18:03.584057Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"BoostedFisher\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFisher, \"BoostedFisher\",\n",
    "                        \"H:!V:Boost_Num=20:Boost_Transform=log:Boost_Type=AdaBoost:Boost_AdaBoostBeta=0.2:!Boost_DetailedMonitoring\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f3ead6",
   "metadata": {},
   "source": [
    "Function discrimination analysis (FDA) -- test of various fitters - the recommended one is Minuit (or GA or SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83eaaa27",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:03.589526Z",
     "iopub.status.busy": "2024-12-13T10:18:03.589214Z",
     "iopub.status.idle": "2024-12-13T10:18:03.927324Z",
     "shell.execute_reply": "2024-12-13T10:18:03.926409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mFDA_GA\u001b[0m\n",
      "                         : \n",
      "                         : Create parameter interval for parameter 0 : [-1,1]\n",
      "                         : Create parameter interval for parameter 1 : [-10,10]\n",
      "                         : Create parameter interval for parameter 2 : [-10,10]\n",
      "                         : Create parameter interval for parameter 3 : [-10,10]\n",
      "                         : Create parameter interval for parameter 4 : [-10,10]\n",
      "                         : User-defined formula string       : \"(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3\"\n",
      "                         : TFormula-compatible formula string: \"[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]\"\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"FDA_MC\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFDA, \"FDA_MC\",\n",
    "                        \"H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=MC:SampleSize=100000:Sigma=0.1\" );\n",
    "\n",
    "if (Use[\"FDA_GA\"]) // can also use Simulated Annealing (SA) algorithm (see Cuts_SA options])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFDA, \"FDA_GA\",\n",
    "                        \"H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=GA:PopSize=100:Cycles=2:Steps=5:Trim=True:SaveBestGen=1\" );\n",
    "\n",
    "if (Use[\"FDA_SA\"]) // can also use Simulated Annealing (SA) algorithm (see Cuts_SA options])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFDA, \"FDA_SA\",\n",
    "                        \"H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=SA:MaxCalls=15000:KernelTemp=IncAdaptive:InitialTemp=1e+6:MinTemp=1e-6:Eps=1e-10:UseDefaultScale\" );\n",
    "\n",
    "if (Use[\"FDA_MT\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFDA, \"FDA_MT\",\n",
    "                        \"H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=2:UseImprove:UseMinos:SetBatch\" );\n",
    "\n",
    "if (Use[\"FDA_GAMT\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFDA, \"FDA_GAMT\",\n",
    "                        \"H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=GA:Converger=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=0:!UseImprove:!UseMinos:SetBatch:Cycles=1:PopSize=5:Steps=5:Trim\" );\n",
    "\n",
    "if (Use[\"FDA_MCMT\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kFDA, \"FDA_MCMT\",\n",
    "                        \"H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=MC:Converger=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=0:!UseImprove:!UseMinos:SetBatch:SampleSize=20\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c37fa",
   "metadata": {},
   "source": [
    "TMVA ANN: MLP (recommended ANN) -- all ANNs in TMVA are Multilayer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a1e2d58",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:03.931137Z",
     "iopub.status.busy": "2024-12-13T10:18:03.930803Z",
     "iopub.status.idle": "2024-12-13T10:18:04.140853Z",
     "shell.execute_reply": "2024-12-13T10:18:04.139891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mMLPBNN\u001b[0m\n",
      "                         : \n",
      "MLPBNN                   : [dataset] : Create Transformation \"N\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "MLPBNN                   : Building Network. \n",
      "                         : Initializing weights\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"MLP\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kMLP, \"MLP\", \"H:!V:NeuronType=tanh:VarTransform=N:NCycles=600:HiddenLayers=N+5:TestRate=5:!UseRegulator\" );\n",
    "\n",
    "if (Use[\"MLPBFGS\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kMLP, \"MLPBFGS\", \"H:!V:NeuronType=tanh:VarTransform=N:NCycles=600:HiddenLayers=N+5:TestRate=5:TrainingMethod=BFGS:!UseRegulator\" );\n",
    "\n",
    "if (Use[\"MLPBNN\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kMLP, \"MLPBNN\", \"H:!V:NeuronType=tanh:VarTransform=N:NCycles=60:HiddenLayers=N+5:TestRate=5:TrainingMethod=BFGS:UseRegulator\" ); // BFGS training with bayesian regulators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8684711",
   "metadata": {},
   "source": [
    "Multi-architecture DNN implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f8fa838",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:04.144687Z",
     "iopub.status.busy": "2024-12-13T10:18:04.144379Z",
     "iopub.status.idle": "2024-12-13T10:18:04.462603Z",
     "shell.execute_reply": "2024-12-13T10:18:04.461710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDNN_CPU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"N\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     Layout: \"TANH|128,TANH|128,TANH|128,LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     InputLayout: \"0|0|0\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"0|0|0\" [The Layout of the batch]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "DNN_CPU                  : [dataset] : Create Transformation \"N\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Will now use the CPU architecture with BLAS and IMT support !\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"DNN_CPU\"] or Use[\"DNN_GPU\"]) {\n",
    "   // General layout.\n",
    "   TString layoutString (\"Layout=TANH|128,TANH|128,TANH|128,LINEAR\");\n",
    "\n",
    "   // Define Training strategy. One could define multiple strategy string separated by the \"|\" delimiter\n",
    "\n",
    "   TString trainingStrategyString = (\"TrainingStrategy=LearningRate=1e-2,Momentum=0.9,\"\n",
    "                                     \"ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,\"\n",
    "                                     \"WeightDecay=1e-4,Regularization=None,\"\n",
    "                                     \"DropConfig=0.0+0.5+0.5+0.5\");\n",
    "\n",
    "   // General Options.\n",
    "   TString dnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:\"\n",
    "                       \"WeightInitialization=XAVIERUNIFORM\");\n",
    "   dnnOptions.Append (\":\"); dnnOptions.Append (layoutString);\n",
    "   dnnOptions.Append (\":\"); dnnOptions.Append (trainingStrategyString);\n",
    "\n",
    "   // Cuda implementation.\n",
    "   if (Use[\"DNN_GPU\"]) {\n",
    "      TString gpuOptions = dnnOptions + \":Architecture=GPU\";\n",
    "      factory->BookMethod(dataloader, TMVA::Types::kDL, \"DNN_GPU\", gpuOptions);\n",
    "   }\n",
    "   // Multi-core CPU implementation.\n",
    "   if (Use[\"DNN_CPU\"]) {\n",
    "      TString cpuOptions = dnnOptions + \":Architecture=CPU\";\n",
    "      factory->BookMethod(dataloader, TMVA::Types::kDL, \"DNN_CPU\", cpuOptions);\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a62f3",
   "metadata": {},
   "source": [
    "CF(Clermont-Ferrand)ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c9ec2c2",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:04.466376Z",
     "iopub.status.busy": "2024-12-13T10:18:04.466090Z",
     "iopub.status.idle": "2024-12-13T10:18:04.674876Z",
     "shell.execute_reply": "2024-12-13T10:18:04.673888Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"CFMlpANN\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kCFMlpANN, \"CFMlpANN\", \"!H:!V:NCycles=200:HiddenLayers=N+1,N\"  ); // n_cycles:#nodes:#nodes:..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d14ada",
   "metadata": {},
   "source": [
    "Tmlp(Root)ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c478c5a",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:04.679227Z",
     "iopub.status.busy": "2024-12-13T10:18:04.678937Z",
     "iopub.status.idle": "2024-12-13T10:18:04.887859Z",
     "shell.execute_reply": "2024-12-13T10:18:04.886702Z"
    }
   },
   "outputs": [],
   "source": [
    "if (Use[\"TMlpANN\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kTMlpANN, \"TMlpANN\", \"!H:!V:NCycles=200:HiddenLayers=N+1,N:LearningMethod=BFGS:ValidationFraction=0.3\"  ); // n_cycles:#nodes:#nodes:..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f6102",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f0efa5f",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:04.892213Z",
     "iopub.status.busy": "2024-12-13T10:18:04.891910Z",
     "iopub.status.idle": "2024-12-13T10:18:05.096677Z",
     "shell.execute_reply": "2024-12-13T10:18:05.095773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mSVM\u001b[0m\n",
      "                         : \n",
      "SVM                      : [dataset] : Create Transformation \"Norm\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"SVM\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kSVM, \"SVM\", \"Gamma=0.25:Tol=0.001:VarTransform=Norm\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b838ce17",
   "metadata": {},
   "source": [
    "Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f076d69c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:05.100492Z",
     "iopub.status.busy": "2024-12-13T10:18:05.100200Z",
     "iopub.status.idle": "2024-12-13T10:18:05.304545Z",
     "shell.execute_reply": "2024-12-13T10:18:05.303656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"BDTG\"]) // Gradient Boost\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kBDT, \"BDTG\",\n",
    "                        \"!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad:Shrinkage=0.10:UseBaggedBoost:BaggedSampleFraction=0.5:nCuts=20:MaxDepth=2\" );\n",
    "\n",
    "if (Use[\"BDT\"])  // Adaptive Boost\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kBDT, \"BDT\",\n",
    "                        \"!H:!V:NTrees=850:MinNodeSize=2.5%:MaxDepth=3:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n",
    "\n",
    "if (Use[\"BDTB\"]) // Bagging\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kBDT, \"BDTB\",\n",
    "                        \"!H:!V:NTrees=400:BoostType=Bagging:SeparationType=GiniIndex:nCuts=20\" );\n",
    "\n",
    "if (Use[\"BDTD\"]) // Decorrelation + Adaptive Boost\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kBDT, \"BDTD\",\n",
    "                        \"!H:!V:NTrees=400:MinNodeSize=5%:MaxDepth=3:BoostType=AdaBoost:SeparationType=GiniIndex:nCuts=20:VarTransform=Decorrelate\" );\n",
    "\n",
    "if (Use[\"BDTF\"])  // Allow Using Fisher discriminant in node splitting for (strong) linearly correlated variables\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kBDT, \"BDTF\",\n",
    "                        \"!H:!V:NTrees=50:MinNodeSize=2.5%:UseFisherCuts:MaxDepth=3:BoostType=AdaBoost:AdaBoostBeta=0.5:SeparationType=GiniIndex:nCuts=20\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca399e",
   "metadata": {},
   "source": [
    "RuleFit -- TMVA implementation of Friedman's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cb79dc1",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:05.308518Z",
     "iopub.status.busy": "2024-12-13T10:18:05.308232Z",
     "iopub.status.idle": "2024-12-13T10:18:05.512746Z",
     "shell.execute_reply": "2024-12-13T10:18:05.511843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mRuleFit\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"RuleFit\"])\n",
    "   factory->BookMethod( dataloader, TMVA::Types::kRuleFit, \"RuleFit\",\n",
    "                        \"H:!V:RuleFitModule=RFTMVA:Model=ModRuleLinear:MinImp=0.001:RuleMinDist=0.001:NTrees=20:fEventsMin=0.01:fEventsMax=0.5:GDTau=-1.0:GDTauPrec=0.01:GDStep=0.01:GDNSteps=10000:GDErrScale=1.02\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d4ecf",
   "metadata": {},
   "source": [
    "For an example of the category classifier usage, see: TMVAClassificationCategory\n",
    "\n",
    "--------------------------------------------------------------------------------------------------\n",
    "Now you can optimize the setting (configuration) of the MVAs using the set of training events\n",
    "STILL EXPERIMENTAL and only implemented for BDT's !\n",
    "\n",
    "factory->OptimizeAllMethods(\"SigEffAtBkg0.01\",\"Scan\");\n",
    "factory->OptimizeAllMethods(\"ROCIntegral\",\"FitGA\");\n",
    "\n",
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16cf851",
   "metadata": {},
   "source": [
    "Now you can tell the factory to train, test, and evaluate the MVAs\n",
    "\n",
    "Train MVAs using the set of training events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d13b7a3b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:05.516754Z",
     "iopub.status.busy": "2024-12-13T10:18:05.516440Z",
     "iopub.status.idle": "2024-12-13T10:18:48.669644Z",
     "shell.execute_reply": "2024-12-13T10:18:48.668654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "Factory                  : [dataset] : Create Transformation \"D\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "Factory                  : [dataset] : Create Transformation \"P\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "Factory                  : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "Factory                  : [dataset] : Create Transformation \"D\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:  -0.062775     1.7187   [    -9.3380     7.6931 ]\n",
      "                         :   myvar2:   0.056495     1.0784   [    -3.2551     4.0291 ]\n",
      "                         :     var3:  -0.020366     1.0633   [    -5.2777     4.6430 ]\n",
      "                         :     var4:    0.13214     1.2464   [    -5.6007     4.6744 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Preparing the Decorrelation transformation...\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]\n",
      "                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]\n",
      "                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]\n",
      "                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Preparing the Principle Component (PCA) transformation...\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.11433     2.2714   [    -11.272     9.0916 ]\n",
      "                         :   myvar2: -0.0070834     1.0934   [    -3.9875     3.3836 ]\n",
      "                         :     var3:   0.011107    0.57824   [    -2.0171     2.1958 ]\n",
      "                         :     var4: -0.0094450    0.33437   [    -1.0176     1.0617 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Preparing the Gaussian transformation...\n",
      "                         : Preparing the Decorrelation transformation...\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:  -0.049483     1.0000   [    -3.0916     8.1528 ]\n",
      "                         :   myvar2: -0.0017889     1.0000   [    -4.5911     5.6465 ]\n",
      "                         :     var3: -0.0056513     1.0000   [    -3.1504     4.5978 ]\n",
      "                         :     var4:   0.070934     1.0000   [    -3.4539     5.9256 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable     : Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : Variable 4   : 2.843e-01\n",
      "                         :    2 : Variable 3   : 1.756e-01\n",
      "                         :    3 : myvar1       : 1.018e-01\n",
      "                         :    4 : Expression 2 : 3.860e-02\n",
      "                         : -------------------------------------\n",
      "Factory                  : Train method: Cuts for Classification\n",
      "                         : \n",
      "FitterBase               : <MCFitter> Sampling, please be patient ...\n",
      "                         : Elapsed time: 6.99 sec                           \n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.1\n",
      "                         : Corresponding background efficiency       : 0.00621902\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -1.19223 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=      2.126\n",
      "                         : Cut[ 2]:   -2.90978 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:    2.16207 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.2\n",
      "                         : Corresponding background efficiency       : 0.0171253\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -5.85714 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    2.21109\n",
      "                         : Cut[ 2]:  -0.759439 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:    1.66846 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.3\n",
      "                         : Corresponding background efficiency       : 0.0401486\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -6.09813 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    2.81831\n",
      "                         : Cut[ 2]:   -2.09336 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:    1.34308 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.4\n",
      "                         : Corresponding background efficiency       : 0.062887\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -4.55141 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    2.94573\n",
      "                         : Cut[ 2]:   -4.68697 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:    1.07157 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.5\n",
      "                         : Corresponding background efficiency       : 0.104486\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -5.86032 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    2.89615\n",
      "                         : Cut[ 2]:  -0.966191 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:   0.773848 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.6\n",
      "                         : Corresponding background efficiency       : 0.172806\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -5.52552 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    4.08498\n",
      "                         : Cut[ 2]:   -2.61706 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:   0.469684 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.7\n",
      "                         : Corresponding background efficiency       : 0.258379\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -5.69875 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    1.73784\n",
      "                         : Cut[ 2]:   -1.21467 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:   0.109026 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.8\n",
      "                         : Corresponding background efficiency       : 0.362964\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -1.99372 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    3.93767\n",
      "                         : Cut[ 2]:   -1.56317 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:  -0.124013 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : ------------------------------------------\n",
      "Cuts                     : Cut values for requested signal efficiency: 0.9\n",
      "                         : Corresponding background efficiency       : 0.503885\n",
      "                         : Transformation applied to input variables : None\n",
      "                         : ------------------------------------------\n",
      "                         : Cut[ 0]:   -3.97304 < myvar1 <=      1e+30\n",
      "                         : Cut[ 1]:     -1e+30 < myvar2 <=    3.31284\n",
      "                         : Cut[ 2]:   -2.82879 <   var3 <=      1e+30\n",
      "                         : Cut[ 3]:  -0.577302 <   var4 <=      1e+30\n",
      "                         : ------------------------------------------\n",
      "                         : Elapsed time for training with 2000 events: 7 sec         \n",
      "Cuts                     : [dataset] : Evaluation of Cuts on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.000167 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_Cuts.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_Cuts.class.C\u001b[0m\n",
      "                         : TMVAC.root:/dataset/Method_Cuts/Cuts\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: CutsD for Classification\n",
      "                         : \n",
      "                         : Preparing the Decorrelation transformation...\n",
      "TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]\n",
      "                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]\n",
      "                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]\n",
      "                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]\n",
      "                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]\n",
      "                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]\n",
      "                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]\n",
      "                         : -----------------------------------------------------------\n",
      "FitterBase               : <MCFitter> Sampling, please be patient ...\n",
      "                         : Elapsed time: 4.08 sec                           \n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.1\n",
      "                         : Corresponding background efficiency       : 0\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=   0.513038\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=  -0.733858\n",
      "                         : Cut[ 2]:   -0.87113 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:   0.687739 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.2\n",
      "                         : Corresponding background efficiency       : 0.000493656\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=    1.60056\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    1.26936\n",
      "                         : Cut[ 2]:   -1.50073 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:    1.54845 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.3\n",
      "                         : Corresponding background efficiency       : 0.00334252\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=    2.16898\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    3.25932\n",
      "                         : Cut[ 2]:   -2.08503 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:    1.43959 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.4\n",
      "                         : Corresponding background efficiency       : 0.00821453\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=     1.9086\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    1.94778\n",
      "                         : Cut[ 2]:   -2.11471 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:     1.1885 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.5\n",
      "                         : Corresponding background efficiency       : 0.0209024\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=    3.97301\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    2.87835\n",
      "                         : Cut[ 2]:   -1.68889 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:   0.969507 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.6\n",
      "                         : Corresponding background efficiency       : 0.055037\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=    2.57624\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    2.20263\n",
      "                         : Cut[ 2]:   -3.86902 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:   0.802122 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.7\n",
      "                         : Corresponding background efficiency       : 0.0975699\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=    3.65719\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    3.19411\n",
      "                         : Cut[ 2]:   -2.87372 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:   0.583961 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.8\n",
      "                         : Corresponding background efficiency       : 0.170999\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=    4.74857\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    2.75269\n",
      "                         : Cut[ 2]:   -3.22043 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:   0.327788 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "CutsD                    : Cut values for requested signal efficiency: 0.9\n",
      "                         : Corresponding background efficiency       : 0.326977\n",
      "                         : Transformation applied to input variables : \"Deco\"\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Cut[ 0]:     -1e+30 <  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] <=    3.56614\n",
      "                         : Cut[ 1]:     -1e+30 <  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] <=    3.09071\n",
      "                         : Cut[ 2]:    -3.9944 <  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] <=      1e+30\n",
      "                         : Cut[ 3]:  0.0311777 <  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] <=      1e+30\n",
      "                         : ------------------------------------------------------------------------------------------------------------------------\n",
      "                         : Elapsed time for training with 2000 events: 4.08 sec         \n",
      "CutsD                    : [dataset] : Evaluation of CutsD on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.00126 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_CutsD.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_CutsD.class.C\u001b[0m\n",
      "                         : TMVAC.root:/dataset/Method_Cuts/CutsD\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: Likelihood for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ Likelihood ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : The maximum-likelihood classifier models the data with probability \n",
      "                         : density functions (PDF) reproducing the signal and background\n",
      "                         : distributions of the input variables. Correlations among the \n",
      "                         : variables are ignored.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Required for good performance are decorrelated input variables\n",
      "                         : (PCA transformation via the option \"VarTransform=Decorrelate\"\n",
      "                         : may be tried). Irreducible non-linear correlations may be reduced\n",
      "                         : by precombining strongly correlated input variables, or by simply\n",
      "                         : removing one of the variables.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : High fidelity PDF estimates are mandatory, i.e., sufficient training \n",
      "                         : statistics is required to populate the tails of the distributions\n",
      "                         : It would be a surprise if the default Spline or KDE kernel parameters\n",
      "                         : provide a satisfying fit to the data. The user is advised to properly\n",
      "                         : tune the events per bin and smooth options in the spline cases\n",
      "                         : individually per variable. If the KDE kernel is used, the adaptive\n",
      "                         : Gaussian kernel may lead to artefacts, so please always also try\n",
      "                         : the non-adaptive one.\n",
      "                         : \n",
      "                         : All tuning parameters must be adjusted individually for each input\n",
      "                         : variable!\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "                         : Filling reference histograms\n",
      "                         : Building PDF out of reference histograms\n",
      "                         : Elapsed time for training with 2000 events: 0.0517 sec         \n",
      "Likelihood               : [dataset] : Evaluation of Likelihood on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.00197 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_Likelihood.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_Likelihood.class.C\u001b[0m\n",
      "                         : TMVAC.root:/dataset/Method_Likelihood/Likelihood\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: LikelihoodPCA for Classification\n",
      "                         : \n",
      "                         : Preparing the Principle Component (PCA) transformation...\n",
      "TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.11433     2.2714   [    -11.272     9.0916 ]\n",
      "                         :   myvar2: -0.0070834     1.0934   [    -3.9875     3.3836 ]\n",
      "                         :     var3:   0.011107    0.57824   [    -2.0171     2.1958 ]\n",
      "                         :     var4: -0.0094450    0.33437   [    -1.0176     1.0617 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Filling reference histograms\n",
      "                         : Building PDF out of reference histograms\n",
      "                         : Elapsed time for training with 2000 events: 0.0404 sec         \n",
      "LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.00381 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_LikelihoodPCA.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_LikelihoodPCA.class.C\u001b[0m\n",
      "                         : TMVAC.root:/dataset/Method_Likelihood/LikelihoodPCA\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: PDERS for Classification\n",
      "                         : \n",
      "                         : Elapsed time for training with 2000 events: 0.00391 sec         \n",
      "PDERS                    : [dataset] : Evaluation of PDERS on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.597 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_PDERS.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_PDERS.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: PDEFoam for Classification\n",
      "                         : \n",
      "PDEFoam                  : NormMode=NUMEVENTS chosen. Note that only NormMode=EqualNumEvents ensures that Discriminant values correspond to signal probabilities.\n",
      "                         : Build up discriminator foam\n",
      "                         : Elapsed time: 0.821 sec                                 \n",
      "                         : Elapsed time for training with 2000 events: 0.89 sec         \n",
      "PDEFoam                  : [dataset] : Evaluation of PDEFoam on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.0299 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_PDEFoam.weights.xml\u001b[0m\n",
      "                         : writing foam DiscrFoam to file\n",
      "                         : Foams written to file: \u001b[0;36mdataset/weights/TMVAClassification_PDEFoam.weights_foams.root\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_PDEFoam.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: KNN for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ KNN ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : The k-nearest neighbor (k-NN) algorithm is a multi-dimensional classification\n",
      "                         : and regression algorithm. Similarly to other TMVA algorithms, k-NN uses a set of\n",
      "                         : training events for which a classification category/regression target is known. \n",
      "                         : The k-NN method compares a test event to all training events using a distance \n",
      "                         : function, which is an Euclidean distance in a space defined by the input variables. \n",
      "                         : The k-NN method, as implemented in TMVA, uses a kd-tree algorithm to perform a\n",
      "                         : quick search for the k events with shortest distance to the test event. The method\n",
      "                         : returns a fraction of signal events among the k neighbors. It is recommended\n",
      "                         : that a histogram which stores the k-NN decision variable is binned with k+1 bins\n",
      "                         : between 0 and 1.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options: \u001b[0m\n",
      "                         : \n",
      "                         : The k-NN method estimates a density of signal and background events in a \n",
      "                         : neighborhood around the test event. The method assumes that the density of the \n",
      "                         : signal and background events is uniform and constant within the neighborhood. \n",
      "                         : k is an adjustable parameter and it determines an average size of the \n",
      "                         : neighborhood. Small k values (less than 10) are sensitive to statistical \n",
      "                         : fluctuations and large (greater than 100) values might not sufficiently capture  \n",
      "                         : local differences between events in the training set. The speed of the k-NN\n",
      "                         : method also increases with larger values of k. \n",
      "                         : \n",
      "                         : The k-NN method assigns equal weight to all input variables. Different scales \n",
      "                         : among the input variables is compensated using ScaleFrac parameter: the input \n",
      "                         : variables are scaled so that the widths for central ScaleFrac*100% events are \n",
      "                         : equal among all the input variables.\n",
      "                         : \n",
      "                         : \u001b[1m--- Additional configuration options: \u001b[0m\n",
      "                         : \n",
      "                         : The method inclues an option to use a Gaussian kernel to smooth out the k-NN\n",
      "                         : response. The kernel re-weights events using a distance to the test event.\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "KNN                      : <Train> start...\n",
      "                         : Reading 2000 events\n",
      "                         : Number of signal events 1000\n",
      "                         : Number of background events 1000\n",
      "                         : Creating kd-tree with 2000 events\n",
      "                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)\n",
      "ModulekNN                : Optimizing tree for 4 variables with 2000 values\n",
      "                         : <Fill> Class 1 has     1000 events\n",
      "                         : <Fill> Class 2 has     1000 events\n",
      "                         : Elapsed time for training with 2000 events: 0.00353 sec         \n",
      "KNN                      : [dataset] : Evaluation of KNN on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.087 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_KNN.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_KNN.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: LD for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ LD ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : Linear discriminants select events by distinguishing the mean \n",
      "                         : values of the signal and background distributions in a trans- \n",
      "                         : formed variable space where linear correlations are removed.\n",
      "                         : The LD implementation here is equivalent to the \"Fisher\" discriminant\n",
      "                         : for classification, but also provides linear regression.\n",
      "                         : \n",
      "                         :    (More precisely: the \"linear discriminator\" determines\n",
      "                         :     an axis in the (correlated) hyperspace of the input \n",
      "                         :     variables such that, when projecting the output classes \n",
      "                         :     (signal and background) upon this axis, they are pushed \n",
      "                         :     as far as possible away from each other, while events\n",
      "                         :     of a same class are confined in a close vicinity. The  \n",
      "                         :     linearity property of this classifier is reflected in the \n",
      "                         :     metric with which \"far apart\" and \"close vicinity\" are \n",
      "                         :     determined: the covariance matrix of the discriminating\n",
      "                         :     variable space.)\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Optimal performance for the linear discriminant is obtained for \n",
      "                         : linearly correlated Gaussian-distributed variables. Any deviation\n",
      "                         : from this ideal reduces the achievable separation power. In \n",
      "                         : particular, no discrimination at all is achieved for a variable\n",
      "                         : that has the same sample mean for signal and background, even if \n",
      "                         : the shapes of the distributions are very different. Thus, the linear \n",
      "                         : discriminant often benefits from a suitable transformation of the \n",
      "                         : input variables. For example, if a variable x in [-1,1] has a \n",
      "                         : a parabolic signal distributions, and a uniform background\n",
      "                         : distributions, their mean value is zero in both cases, leading \n",
      "                         : to no separation. The simple transformation x -> |x| renders this \n",
      "                         : variable powerful for the use in a linear discriminant.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : <None>\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "LD                       : Results for LD coefficients:\n",
      "                         : -----------------------\n",
      "                         : Variable:  Coefficient:\n",
      "                         : -----------------------\n",
      "                         :   myvar1:       -0.309\n",
      "                         :   myvar2:       -0.102\n",
      "                         :     var3:       -0.142\n",
      "                         :     var4:       +0.705\n",
      "                         : (offset):       -0.055\n",
      "                         : -----------------------\n",
      "                         : Elapsed time for training with 2000 events: 0.0012 sec         \n",
      "LD                       : [dataset] : Evaluation of LD on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.000184 sec       \n",
      "                         : <CreateMVAPdfs> Separation from histogram (PDF): 0.540 (0.000)\n",
      "                         : Dataset[dataset] : Evaluation of LD on training sample\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_LD.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_LD.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: FDA_GA for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ FDA_GA ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : The function discriminant analysis (FDA) is a classifier suitable \n",
      "                         : to solve linear or simple nonlinear discrimination problems.\n",
      "                         : \n",
      "                         : The user provides the desired function with adjustable parameters\n",
      "                         : via the configuration option string, and FDA fits the parameters to\n",
      "                         : it, requiring the signal (background) function value to be as close\n",
      "                         : as possible to 1 (0). Its advantage over the more involved and\n",
      "                         : automatic nonlinear discriminators is the simplicity and transparency \n",
      "                         : of the discrimination expression. A shortcoming is that FDA will\n",
      "                         : underperform for involved problems with complicated, phase space\n",
      "                         : dependent nonlinear correlations.\n",
      "                         : \n",
      "                         : Please consult the Users Guide for the format of the formula string\n",
      "                         : and the allowed parameter ranges:\n",
      "                         : documentation/tmva/UsersGuide/TMVAUsersGuide.pdf\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : The FDA performance depends on the complexity and fidelity of the\n",
      "                         : user-defined discriminator function. As a general rule, it should\n",
      "                         : be able to reproduce the discrimination power of any linear\n",
      "                         : discriminant analysis. To reach into the nonlinear domain, it is\n",
      "                         : useful to inspect the correlation profiles of the input variables,\n",
      "                         : and add quadratic and higher polynomial terms between variables as\n",
      "                         : necessary. Comparison with more involved nonlinear classifiers can\n",
      "                         : be used as a guide.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : Depending on the function used, the choice of \"FitMethod\" is\n",
      "                         : crucial for getting valuable solutions with FDA. As a guideline it\n",
      "                         : is recommended to start with \"FitMethod=MINUIT\". When more complex\n",
      "                         : functions are used where MINUIT does not converge to reasonable\n",
      "                         : results, the user should switch to non-gradient FitMethods such\n",
      "                         : as GeneticAlgorithm (GA) or Monte Carlo (MC). It might prove to be\n",
      "                         : useful to combine GA (or MC) with MINUIT by setting the option\n",
      "                         : \"Converger=MINUIT\". GA (MC) will then set the starting parameters\n",
      "                         : for MINUIT such that the basic quality of GA (MC) of finding global\n",
      "                         : minima is combined with the efficacy of MINUIT of finding local\n",
      "                         : minima.\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "FitterBase               : <GeneticFitter> Optimisation, please be patient ... (inaccurate progress timing for GA)\n",
      "                         : Elapsed time: 1.89 sec                            \n",
      "FDA_GA                   : Results for parameter fit using \"GA\" fitter:\n",
      "                         : -----------------------\n",
      "                         : Parameter:  Fit result:\n",
      "                         : -----------------------\n",
      "                         :    Par(0):     0.48449\n",
      "                         :    Par(1):           0\n",
      "                         :    Par(2):   -0.103082\n",
      "                         :    Par(3):           0\n",
      "                         :    Par(4):    0.168653\n",
      "                         : -----------------------\n",
      "                         : Discriminator expression: \"(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3\"\n",
      "                         : Value of estimator at minimum: 0.366833\n",
      "                         : Elapsed time for training with 2000 events: 1.96 sec         \n",
      "FDA_GA                   : [dataset] : Evaluation of FDA_GA on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.000245 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_FDA_GA.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_FDA_GA.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: MLPBNN for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ MLPBNN ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : The MLP artificial neural network (ANN) is a traditional feed-\n",
      "                         : forward multilayer perceptron implementation. The MLP has a user-\n",
      "                         : defined hidden layer architecture, while the number of input (output)\n",
      "                         : nodes is determined by the input variables (output classes, i.e., \n",
      "                         : signal and one background). \n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Neural networks are stable and performing for a large variety of \n",
      "                         : linear and non-linear classification problems. However, in contrast\n",
      "                         : to (e.g.) boosted decision trees, the user is advised to reduce the \n",
      "                         : number of input variables that have only little discrimination power. \n",
      "                         : \n",
      "                         : In the tests we have carried out so far, the MLP and ROOT networks\n",
      "                         : (TMlpANN, interfaced via TMVA) performed equally well, with however\n",
      "                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural \n",
      "                         : net (CFMlpANN) exhibited worse classification performance in these\n",
      "                         : tests, which is partly due to the slow convergence of its training\n",
      "                         : (at least 10k training cycles are required to achieve approximately\n",
      "                         : competitive results).\n",
      "                         : \n",
      "                         : \u001b[1mOvertraining: \u001b[0monly the TMlpANN performs an explicit separation of the\n",
      "                         : full training sample into independent training and validation samples.\n",
      "                         : We have found that in most high-energy physics applications the \n",
      "                         : available degrees of freedom (training events) are sufficient to \n",
      "                         : constrain the weights of the relatively simple architectures required\n",
      "                         : to achieve good performance. Hence no overtraining should occur, and \n",
      "                         : the use of validation samples would only reduce the available training\n",
      "                         : information. However, if the performance on the training sample is \n",
      "                         : found to be significantly better than the one found with the inde-\n",
      "                         : pendent test sample, caution is needed. The results for these samples \n",
      "                         : are printed to standard output at the end of each training job.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : The hidden layer architecture for all ANNs is defined by the option\n",
      "                         : \"HiddenLayers=N+1,N,...\", where here the first hidden layer has N+1\n",
      "                         : neurons and the second N neurons (and so on), and where N is the number  \n",
      "                         : of input variables. Excessive numbers of hidden layers should be avoided,\n",
      "                         : in favour of more neurons in the first hidden layer.\n",
      "                         : \n",
      "                         : The number of cycles should be above 500. As said, if the number of\n",
      "                         : adjustable weights is small compared to the training sample size,\n",
      "                         : using a large number of training samples should not lead to overtraining.\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]\n",
      "                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]\n",
      "                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]\n",
      "                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Training Network\n",
      "                         : \n",
      "                         : Finalizing handling of Regulator terms, trainE=0.713219 testE=0.724617\n",
      "                         : Done with handling of Regulator terms\n",
      "                         : Elapsed time for training with 2000 events: 6.03 sec         \n",
      "MLPBNN                   : [dataset] : Evaluation of MLPBNN on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.00609 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_MLPBNN.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_MLPBNN.class.C\u001b[0m\n",
      "                         : Write special histos to file: TMVAC.root:/dataset/Method_MLP/MLPBNN\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DNN_CPU for Classification\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]\n",
      "                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]\n",
      "                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]\n",
      "                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Start of deep neural network training on CPU using MT,  nthreads = 1\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]\n",
      "                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]\n",
      "                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]\n",
      "                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 4  Input = ( 1, 1, 4 )  Batch size = 100  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =     4 , Width =   128 ) \tOutput = (  1 ,   100 ,   128 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t ( Input =   128 , Width =   128 ) \tOutput = (  1 ,   100 ,   128 ) \t Activation Function = Tanh\t Dropout prob. = 0.5\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =   128 , Width =   128 ) \tOutput = (  1 ,   100 ,   128 ) \t Activation Function = Tanh\t Dropout prob. = 0.5\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =   128 , Width =     1 ) \tOutput = (  1 ,   100 ,     1 ) \t Activation Function = Identity\t Dropout prob. = 0.5\n",
      "                         : Using 1600 events for training and 400 for testing\n",
      "                         : Compute initial loss  on the validation data \n",
      "                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.01 regularization 0 minimum error = 0.695964\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :    Start epoch iteration ...\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.514998    0.448394    0.350798   0.0150145     4764.97           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.415738    0.380588    0.198853   0.0156263     8732.37           0\n",
      "                         :          3 |     0.418855    0.426657    0.198021   0.0144131     8714.22           1\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.407729    0.379691    0.254415   0.0302721      7138.3           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |      0.41778    0.374949    0.403597   0.0303545     4286.76           0\n",
      "                         :          6 |     0.413798     0.40404    0.401569   0.0304079      4310.8           1\n",
      "                         :          7 |     0.392988     0.43041    0.582096   0.0299143      2897.6           2\n",
      "                         :          8 |     0.410082    0.396359    0.257938   0.0400792      7344.2           3\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.388327    0.372394    0.205899   0.0148698     8375.68           0\n",
      "                         :         10 |     0.405131    0.386579    0.197265   0.0145723     8757.88           1\n",
      "                         :         11 |     0.389083    0.373604    0.199933   0.0147511     8640.17           2\n",
      "                         :         12 |     0.386433    0.395763    0.198667   0.0143733     8681.79           3\n",
      "                         :         13 |     0.390998    0.405447    0.317232   0.0240885     5458.08           4\n",
      "                         :         14 |     0.391682    0.388871    0.309769   0.0162335     5450.79           5\n",
      "                         :         15 |      0.39872    0.380815    0.198896    0.014394     8671.98           6\n",
      "                         :         16 |     0.395382    0.389155    0.205996   0.0150347     8378.68           7\n",
      "                         :         17 |      0.39687    0.386033    0.216258   0.0145152     7930.89           8\n",
      "                         :         18 |     0.387808    0.384201    0.196622   0.0145824     8789.27           9\n",
      "                         :         19 |     0.388044     0.38085    0.195926    0.014456      8816.9          10\n",
      "                         :         20 |     0.389544    0.384172    0.204045   0.0145519      8443.6          11\n",
      "                         :         21 |     0.395263     0.40324    0.200811    0.017254     8716.63          12\n",
      "                         :         22 |     0.422826    0.385905    0.199272   0.0145556     8661.94          13\n",
      "                         :         23 |     0.396463    0.390318    0.549101    0.266889      5669.5          14\n",
      "                         :         24 |     0.381245    0.404834    0.200907   0.0148862     8601.17          15\n",
      "                         :         25 Minimum Test error found - save the configuration \n",
      "                         :         25 |      0.39001    0.370872    0.203874   0.0151351     8477.33           0\n",
      "                         :         26 |      0.37694    0.384064     0.21061   0.0159608     8219.91           1\n",
      "                         :         27 |     0.405043    0.389877    0.206002    0.014776     8367.05           2\n",
      "                         :         28 |     0.389693    0.382918    0.212688   0.0185831     8242.96           3\n",
      "                         :         29 |     0.391036    0.379109    0.217467   0.0149017     7898.69           4\n",
      "                         :         30 |     0.398019    0.415629    0.409123    0.015305     4062.79           5\n",
      "                         :         31 |      0.40266    0.376457    0.219971   0.0151387     7811.26           6\n",
      "                         :         32 |     0.401223    0.378911    0.205766    0.014529     8366.59           7\n",
      "                         :         33 |     0.402907     0.38665    0.207288   0.0151549     8327.58           8\n",
      "                         :         34 |     0.384279    0.396148    0.206555    0.014664     8338.07           9\n",
      "                         :         35 |      0.38812     0.40085    0.197811   0.0146586     8735.88          10\n",
      "                         :         36 |     0.389311    0.400736    0.291343   0.0267872     6047.87          11\n",
      "                         :         37 |     0.399816    0.409018    0.748607   0.0381587      2252.1          12\n",
      "                         :         38 |     0.396314    0.373371     0.34796   0.0341741     5099.01          13\n",
      "                         :         39 |      0.39098    0.372442    0.303296   0.0163636     5576.22          14\n",
      "                         :         40 |     0.385056    0.398044    0.318217   0.0350719     5650.81          15\n",
      "                         :         41 |      0.39615    0.375239    0.268629   0.0184851     6396.33          16\n",
      "                         :         42 |     0.408128    0.414275    0.573002   0.0221696      2904.7          17\n",
      "                         :         43 |     0.411191     0.40891     0.29829    0.022709     5805.92          18\n",
      "                         :         44 |     0.396687    0.399634     0.26979   0.0145279     6268.06          19\n",
      "                         :         45 |     0.408052    0.391778    0.199151   0.0145322      8666.5          20\n",
      "                         :         46 |     0.387527    0.371969    0.224727   0.0157802     7657.45          21\n",
      "                         : \n",
      "                         : Elapsed time for training with 2000 events: 12.8 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 100\n",
      "                         : \n",
      "DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.0789 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_DNN_CPU.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_DNN_CPU.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: SVM for Classification\n",
      "                         : \n",
      "TFHandler_SVM            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]\n",
      "                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]\n",
      "                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]\n",
      "                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Building SVM Working Set...with 2000 event instances\n",
      "                         : Elapsed time for Working Set build: 0.0844 sec\n",
      "                         : Sorry, no computing time forecast available for SVM, please wait ...\n",
      "                         : Elapsed time: 0.465 sec                                          \n",
      "                         : Elapsed time for training with 2000 events: 0.554 sec         \n",
      "SVM                      : [dataset] : Evaluation of SVM on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.0804 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_SVM.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_SVM.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 1000 bkg: 1000\n",
      "                         : #events: (unweighted) sig: 1000 bkg: 1000\n",
      "                         : Training 850 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 2000 events: 0.649 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.153 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_BDT.class.C\u001b[0m\n",
      "                         : TMVAC.root:/dataset/Method_BDT/BDT\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: RuleFit for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ RuleFit ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : This method uses a collection of so called rules to create a\n",
      "                         : discriminating scoring function. Each rule consists of a series\n",
      "                         : of cuts in parameter space. The ensemble of rules are created\n",
      "                         : from a forest of decision trees, trained using the training data.\n",
      "                         : Each node (apart from the root) corresponds to one rule.\n",
      "                         : The scoring function is then obtained by linearly combining\n",
      "                         : the rules. A fitting procedure is applied to find the optimum\n",
      "                         : set of coefficients. The goal is to find a model with few rules\n",
      "                         : but with a strong discriminating power.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : There are two important considerations to make when optimising:\n",
      "                         : \n",
      "                         :   1. Topology of the decision tree forest\n",
      "                         :   2. Fitting of the coefficients\n",
      "                         : \n",
      "                         : The maximum complexity of the rules is defined by the size of\n",
      "                         : the trees. Large trees will yield many complex rules and capture\n",
      "                         : higher order correlations. On the other hand, small trees will\n",
      "                         : lead to a smaller ensemble with simple rules, only capable of\n",
      "                         : modeling simple structures.\n",
      "                         : Several parameters exists for controlling the complexity of the\n",
      "                         : rule ensemble.\n",
      "                         : \n",
      "                         : The fitting procedure searches for a minimum using a gradient\n",
      "                         : directed path. Apart from step size and number of steps, the\n",
      "                         : evolution of the path is defined by a cut-off parameter, tau.\n",
      "                         : This parameter is unknown and depends on the training data.\n",
      "                         : A large value will tend to give large weights to a few rules.\n",
      "                         : Similarly, a small value will lead to a large set of rules\n",
      "                         : with similar weights.\n",
      "                         : \n",
      "                         : A final point is the model used; rules and/or linear terms.\n",
      "                         : For a given training sample, the result may improve by adding\n",
      "                         : linear terms. If best performance is obtained using only linear\n",
      "                         : terms, it is very likely that the Fisher discriminant would be\n",
      "                         : a better choice. Ideally the fitting procedure should be able to\n",
      "                         : make this choice by giving appropriate weights for either terms.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : I.  TUNING OF RULE ENSEMBLE:\n",
      "                         : \n",
      "                         :    \u001b[1mForestType  \u001b[0m: Recommended is to use the default \"AdaBoost\".\n",
      "                         :    \u001b[1mnTrees      \u001b[0m: More trees leads to more rules but also slow\n",
      "                         :                  performance. With too few trees the risk is\n",
      "                         :                  that the rule ensemble becomes too simple.\n",
      "                         :    \u001b[1mfEventsMin  \u001b[0m\n",
      "                         :    \u001b[1mfEventsMax  \u001b[0m: With a lower min, more large trees will be generated\n",
      "                         :                  leading to more complex rules.\n",
      "                         :                  With a higher max, more small trees will be\n",
      "                         :                  generated leading to more simple rules.\n",
      "                         :                  By changing this range, the average complexity\n",
      "                         :                  of the rule ensemble can be controlled.\n",
      "                         :    \u001b[1mRuleMinDist \u001b[0m: By increasing the minimum distance between\n",
      "                         :                  rules, fewer and more diverse rules will remain.\n",
      "                         :                  Initially it is a good idea to keep this small\n",
      "                         :                  or zero and let the fitting do the selection of\n",
      "                         :                  rules. In order to reduce the ensemble size,\n",
      "                         :                  the value can then be increased.\n",
      "                         : \n",
      "                         : II. TUNING OF THE FITTING:\n",
      "                         : \n",
      "                         :    \u001b[1mGDPathEveFrac \u001b[0m: fraction of events in path evaluation\n",
      "                         :                  Increasing this fraction will improve the path\n",
      "                         :                  finding. However, a too high value will give few\n",
      "                         :                  unique events available for error estimation.\n",
      "                         :                  It is recommended to use the default = 0.5.\n",
      "                         :    \u001b[1mGDTau         \u001b[0m: cutoff parameter tau\n",
      "                         :                  By default this value is set to -1.0.\n",
      "                         :                  This means that the cut off parameter is\n",
      "                         :                  automatically estimated. In most cases\n",
      "                         :                  this should be fine. However, you may want\n",
      "                         :                  to fix this value if you already know it\n",
      "                         :                  and want to reduce on training time.\n",
      "                         :    \u001b[1mGDTauPrec     \u001b[0m: precision of estimated tau\n",
      "                         :                  Increase this precision to find a more\n",
      "                         :                  optimum cut-off parameter.\n",
      "                         :    \u001b[1mGDNStep       \u001b[0m: number of steps in path search\n",
      "                         :                  If the number of steps is too small, then\n",
      "                         :                  the program will give a warning message.\n",
      "                         : \n",
      "                         : III. WARNING MESSAGES\n",
      "                         : \n",
      "                         : \u001b[1mRisk(i+1)>=Risk(i) in path\u001b[0m\n",
      "                         : \u001b[1mChaotic behaviour of risk evolution.\u001b[0m\n",
      "                         :                  The error rate was still decreasing at the end\n",
      "                         :                  By construction the Risk should always decrease.\n",
      "                         :                  However, if the training sample is too small or\n",
      "                         :                  the model is overtrained, such warnings can\n",
      "                         :                  occur.\n",
      "                         :                  The warnings can safely be ignored if only a\n",
      "                         :                  few (<3) occur. If more warnings are generated,\n",
      "                         :                  the fitting fails.\n",
      "                         :                  A remedy may be to increase the value\n",
      "                         :                  \u001b[1mGDValidEveFrac\u001b[0m to 1.0 (or a larger value).\n",
      "                         :                  In addition, if \u001b[1mGDPathEveFrac\u001b[0m is too high\n",
      "                         :                  the same warnings may occur since the events\n",
      "                         :                  used for error estimation are also used for\n",
      "                         :                  path estimation.\n",
      "                         :                  Another possibility is to modify the model - \n",
      "                         :                  See above on tuning the rule ensemble.\n",
      "                         : \n",
      "                         : \u001b[1mThe error rate was still decreasing at the end of the path\u001b[0m\n",
      "                         :                  Too few steps in path! Increase \u001b[1mGDNSteps\u001b[0m.\n",
      "                         : \n",
      "                         : \u001b[1mReached minimum early in the search\u001b[0m\n",
      "                         :                  Minimum was found early in the fitting. This\n",
      "                         :                  may indicate that the used step size \u001b[1mGDStep\u001b[0m.\n",
      "                         :                  was too large. Reduce it and rerun.\n",
      "                         :                  If the results still are not OK, modify the\n",
      "                         :                  model either by modifying the rule ensemble\n",
      "                         :                  or add/remove linear terms\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "RuleFit                  : -------------------RULE ENSEMBLE SUMMARY------------------------\n",
      "                         : Tree training method               : AdaBoost\n",
      "                         : Number of events per tree          : 2000\n",
      "                         : Number of trees                    : 20\n",
      "                         : Number of generated rules          : 196\n",
      "                         : Idem, after cleanup                : 80\n",
      "                         : Average number of cuts per rule    :     3.01\n",
      "                         : Spread in number of cuts per rules :     1.23\n",
      "                         : ----------------------------------------------------------------\n",
      "                         : \n",
      "                         : GD path scan - the scan stops when the max num. of steps is reached or a min is found\n",
      "                         : Estimating the cutoff parameter tau. The estimated time is a pessimistic maximum.\n",
      "                         : Best path found with tau = 0.0000 after 3.17 sec      \n",
      "                         : Fitting model...\n",
      "<WARNING>                : \n",
      "                         : Minimisation elapsed time : 1.67 sec                      \n",
      "                         : ----------------------------------------------------------------\n",
      "                         : Found minimum at step 10000 with error = 0.552378\n",
      "                         : Reason for ending loop: end of loop reached\n",
      "                         : ----------------------------------------------------------------\n",
      "                         : The error rate was still decreasing at the end of the path\n",
      "                         : Increase number of steps (GDNSteps).\n",
      "                         : Removed 28 out of a total of 80 rules with importance < 0.001\n",
      "                         : \n",
      "                         : ================================================================\n",
      "                         :                           M o d e l                             \n",
      "                         : ================================================================\n",
      "RuleFit                  : Offset (a0) = 9.46803\n",
      "                         : ------------------------------------\n",
      "                         : Linear model (weights unnormalised)\n",
      "                         : ------------------------------------\n",
      "                         : Variable :     Weights : Importance\n",
      "                         : ------------------------------------\n",
      "                         :   myvar1 :  -6.338e-01 :  0.472\n",
      "                         :   myvar2 :  -4.488e-01 :  0.209\n",
      "                         :     var3 :  -2.810e-01 :  0.129\n",
      "                         :     var4 :   1.850e+00 :  1.000\n",
      "                         : ------------------------------------\n",
      "                         : Number of rules = 52\n",
      "                         : Printing the first 10 rules, ordered in importance.\n",
      "                         : Rule    1 : Importance  = 0.4294\n",
      "                         :             Cut  1 :     -0.708 < var4             \n",
      "                         : Rule    2 : Importance  = 0.3676\n",
      "                         :             Cut  1 :              var3 <    -0.0812\n",
      "                         : Rule    3 : Importance  = 0.3363\n",
      "                         :             Cut  1 :    -0.0812 < var3             \n",
      "                         : Rule    4 : Importance  = 0.2934\n",
      "                         :             Cut  1 :     -0.877 < var3             \n",
      "                         :             Cut  2 :      0.271 < var4             \n",
      "                         : Rule    5 : Importance  = 0.2706\n",
      "                         :             Cut  1 :              myvar1 <       2.83\n",
      "                         :             Cut  2 :      -1.67 < var3             \n",
      "                         : Rule    6 : Importance  = 0.2387\n",
      "                         :             Cut  1 :              myvar1 <       1.46\n",
      "                         :             Cut  2 :              var4 <      0.271\n",
      "                         : Rule    7 : Importance  = 0.1904\n",
      "                         :             Cut  1 :              var4 <     -0.708\n",
      "                         : Rule    8 : Importance  = 0.1897\n",
      "                         :             Cut  1 :              var3 <      0.256\n",
      "                         :             Cut  2 :              var4 <     -0.708\n",
      "                         : Rule    9 : Importance  = 0.1689\n",
      "                         :             Cut  1 :              myvar1 <      -2.85\n",
      "                         : Rule   10 : Importance  = 0.1611\n",
      "                         :             Cut  1 :      -2.85 < myvar1 <       2.68\n",
      "                         : Skipping the next 42 rules\n",
      "                         : ================================================================\n",
      "                         : \n",
      "<WARNING>                : No input variable directory found - BUG?\n",
      "                         : Elapsed time for training with 2000 events: 4.88 sec         \n",
      "RuleFit                  : [dataset] : Evaluation of RuleFit on training sample (2000 events)\n",
      "                         : Elapsed time for evaluation of 2000 events: 0.00215 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_RuleFit.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_RuleFit.class.C\u001b[0m\n",
      "                         : TMVAC.root:/dataset/Method_RuleFit/RuleFit\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "                         : No variable ranking supplied by classifier: Cuts\n",
      "                         : No variable ranking supplied by classifier: CutsD\n",
      "Likelihood               : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable  : Delta Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : var4      : 5.959e-02\n",
      "                         :    2 : myvar1    : 3.033e-04\n",
      "                         :    3 : myvar2    : -2.045e-02\n",
      "                         :    4 : var3      : -2.655e-02\n",
      "                         : -------------------------------------\n",
      "LikelihoodPCA            : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable  : Delta Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : var4      : 2.888e-01\n",
      "                         :    2 : myvar1    : 6.310e-02\n",
      "                         :    3 : var3      : 1.768e-02\n",
      "                         :    4 : myvar2    : 1.165e-02\n",
      "                         : -------------------------------------\n",
      "                         : No variable ranking supplied by classifier: PDERS\n",
      "PDEFoam                  : Ranking result (top variable is best ranked)\n",
      "                         : ----------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : ----------------------------------------\n",
      "                         :    1 : var4      : 3.830e-01\n",
      "                         :    2 : myvar1    : 2.979e-01\n",
      "                         :    3 : var3      : 1.915e-01\n",
      "                         :    4 : myvar2    : 1.277e-01\n",
      "                         : ----------------------------------------\n",
      "                         : No variable ranking supplied by classifier: KNN\n",
      "LD                       : Ranking result (top variable is best ranked)\n",
      "                         : ---------------------------------\n",
      "                         : Rank : Variable  : Discr. power\n",
      "                         : ---------------------------------\n",
      "                         :    1 : var4      : 7.053e-01\n",
      "                         :    2 : myvar1    : 3.094e-01\n",
      "                         :    3 : var3      : 1.423e-01\n",
      "                         :    4 : myvar2    : 1.019e-01\n",
      "                         : ---------------------------------\n",
      "                         : No variable ranking supplied by classifier: FDA_GA\n",
      "MLPBNN                   : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------\n",
      "                         : Rank : Variable  : Importance\n",
      "                         : -------------------------------\n",
      "                         :    1 : var4      : 1.360e+00\n",
      "                         :    2 : myvar2    : 1.009e+00\n",
      "                         :    3 : myvar1    : 8.834e-01\n",
      "                         :    4 : var3      : 3.562e-01\n",
      "                         : -------------------------------\n",
      "                         : No variable ranking supplied by classifier: DNN_CPU\n",
      "                         : No variable ranking supplied by classifier: SVM\n",
      "BDT                      : Ranking result (top variable is best ranked)\n",
      "                         : ----------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : ----------------------------------------\n",
      "                         :    1 : var4      : 2.697e-01\n",
      "                         :    2 : myvar1    : 2.467e-01\n",
      "                         :    3 : myvar2    : 2.460e-01\n",
      "                         :    4 : var3      : 2.377e-01\n",
      "                         : ----------------------------------------\n",
      "RuleFit                  : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------\n",
      "                         : Rank : Variable  : Importance\n",
      "                         : -------------------------------\n",
      "                         :    1 : var4      : 1.000e+00\n",
      "                         :    2 : myvar1    : 6.981e-01\n",
      "                         :    3 : var3      : 5.947e-01\n",
      "                         :    4 : myvar2    : 4.105e-01\n",
      "                         : -------------------------------\n",
      "TH1.Print Name  = TrainingHistory_DNN_CPU_trainingError, Entries= 0, Total sum= 18.3949\n",
      "TH1.Print Name  = TrainingHistory_DNN_CPU_valError, Entries= 0, Total sum= 18.0302\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_Cuts.weights.xml\u001b[0m\n",
      "                         : Read cuts optimised using sample of MC events\n",
      "                         : Reading 100 signal efficiency bins for 4 variables\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_CutsD.weights.xml\u001b[0m\n",
      "                         : Read cuts optimised using sample of MC events\n",
      "                         : Reading 100 signal efficiency bins for 4 variables\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_Likelihood.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_LikelihoodPCA.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_PDERS.weights.xml\u001b[0m\n",
      "                         : signal and background scales: 0.001 0.001\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_PDEFoam.weights.xml\u001b[0m\n",
      "                         : Read foams from file: \u001b[0;36mdataset/weights/TMVAClassification_PDEFoam.weights_foams.root\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_KNN.weights.xml\u001b[0m\n",
      "                         : Creating kd-tree with 2000 events\n",
      "                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)\n",
      "ModulekNN                : Optimizing tree for 4 variables with 2000 values\n",
      "                         : <Fill> Class 1 has     1000 events\n",
      "                         : <Fill> Class 2 has     1000 events\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_LD.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_FDA_GA.weights.xml\u001b[0m\n",
      "                         : User-defined formula string       : \"(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3\"\n",
      "                         : TFormula-compatible formula string: \"[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]\"\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_MLPBNN.weights.xml\u001b[0m\n",
      "MLPBNN                   : Building Network. \n",
      "                         : Initializing weights\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_DNN_CPU.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_SVM.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_BDT.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_RuleFit.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory->TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158eb07d",
   "metadata": {},
   "source": [
    "Evaluate all MVAs using the set of test events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2fee383",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:48.676343Z",
     "iopub.status.busy": "2024-12-13T10:18:48.676016Z",
     "iopub.status.idle": "2024-12-13T10:18:52.988366Z",
     "shell.execute_reply": "2024-12-13T10:18:52.987382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: Cuts for Classification performance\n",
      "                         : \n",
      "Cuts                     : [dataset] : Evaluation of Cuts on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.000566 sec       \n",
      "Factory                  : Test method: CutsD for Classification performance\n",
      "                         : \n",
      "CutsD                    : [dataset] : Evaluation of CutsD on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0071 sec       \n",
      "Factory                  : Test method: Likelihood for Classification performance\n",
      "                         : \n",
      "Likelihood               : [dataset] : Evaluation of Likelihood on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0627 sec       \n",
      "Factory                  : Test method: LikelihoodPCA for Classification performance\n",
      "                         : \n",
      "LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0491 sec       \n",
      "Factory                  : Test method: PDERS for Classification performance\n",
      "                         : \n",
      "PDERS                    : [dataset] : Evaluation of PDERS on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 1.71 sec       \n",
      "Factory                  : Test method: PDEFoam for Classification performance\n",
      "                         : \n",
      "PDEFoam                  : [dataset] : Evaluation of PDEFoam on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0706 sec       \n",
      "Factory                  : Test method: KNN for Classification performance\n",
      "                         : \n",
      "KNN                      : [dataset] : Evaluation of KNN on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.193 sec       \n",
      "Factory                  : Test method: LD for Classification performance\n",
      "                         : \n",
      "LD                       : [dataset] : Evaluation of LD on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.00192 sec       \n",
      "                         : Dataset[dataset] : Evaluation of LD on testing sample\n",
      "Factory                  : Test method: FDA_GA for Classification performance\n",
      "                         : \n",
      "FDA_GA                   : [dataset] : Evaluation of FDA_GA on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.00114 sec       \n",
      "Factory                  : Test method: MLPBNN for Classification performance\n",
      "                         : \n",
      "MLPBNN                   : [dataset] : Evaluation of MLPBNN on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.017 sec       \n",
      "Factory                  : Test method: DNN_CPU for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]\n",
      "                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]\n",
      "                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]\n",
      "                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]\n",
      "                         : -----------------------------------------------------------\n",
      "DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.431 sec       \n",
      "Factory                  : Test method: SVM for Classification performance\n",
      "                         : \n",
      "SVM                      : [dataset] : Evaluation of SVM on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.816 sec       \n",
      "Factory                  : Test method: BDT for Classification performance\n",
      "                         : \n",
      "BDT                      : [dataset] : Evaluation of BDT on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.669 sec       \n",
      "Factory                  : Test method: RuleFit for Classification performance\n",
      "                         : \n",
      "RuleFit                  : [dataset] : Evaluation of RuleFit on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0183 sec       \n"
     ]
    }
   ],
   "source": [
    "factory->TestAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5be520",
   "metadata": {},
   "source": [
    "Evaluate and compare performance of all configured MVAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e93a78b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:18:52.992371Z",
     "iopub.status.busy": "2024-12-13T10:18:52.992068Z",
     "iopub.status.idle": "2024-12-13T10:19:00.221943Z",
     "shell.execute_reply": "2024-12-13T10:19:00.217361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: Cuts\n",
      "                         : \n",
      "<WARNING>                : You have asked for histogram MVA_EFF_BvsS which does not seem to exist in *Results* .. better don't use it \n",
      "<WARNING>                : You have asked for histogram EFF_BVSS_TR which does not seem to exist in *Results* .. better don't use it \n",
      "TFHandler_Cuts           : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: CutsD\n",
      "                         : \n",
      "<WARNING>                : You have asked for histogram MVA_EFF_BvsS which does not seem to exist in *Results* .. better don't use it \n",
      "TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.14555     1.0166   [    -5.5736     5.0206 ]\n",
      "                         :   myvar2:  -0.093417     1.0353   [    -3.8442     3.7856 ]\n",
      "                         :     var3:  -0.096857     1.0078   [    -4.5469     4.5058 ]\n",
      "                         :     var4:    0.65748    0.95864   [    -4.0893     3.7760 ]\n",
      "                         : -----------------------------------------------------------\n",
      "<WARNING>                : You have asked for histogram EFF_BVSS_TR which does not seem to exist in *Results* .. better don't use it \n",
      "TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]\n",
      "                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]\n",
      "                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]\n",
      "                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   -0.14555     1.0166   [    -5.5736     5.0206 ]\n",
      "                         :   myvar2:  -0.093417     1.0353   [    -3.8442     3.7856 ]\n",
      "                         :     var3:  -0.096857     1.0078   [    -4.5469     4.5058 ]\n",
      "                         :     var4:    0.65748    0.95864   [    -4.0893     3.7760 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: Likelihood\n",
      "                         : \n",
      "Likelihood               : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_Likelihood     : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: LikelihoodPCA\n",
      "                         : \n",
      "TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:     1.1147     2.2628   [    -12.508     10.719 ]\n",
      "                         :   myvar2:   -0.25554     1.1225   [    -4.1578     3.8995 ]\n",
      "                         :     var3:   -0.19401    0.58225   [    -2.2950     1.8880 ]\n",
      "                         :     var4:   -0.32038    0.33412   [    -1.3929    0.88819 ]\n",
      "                         : -----------------------------------------------------------\n",
      "LikelihoodPCA            : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:     1.1147     2.2628   [    -12.508     10.719 ]\n",
      "                         :   myvar2:   -0.25554     1.1225   [    -4.1578     3.8995 ]\n",
      "                         :     var3:   -0.19401    0.58225   [    -2.2950     1.8880 ]\n",
      "                         :     var4:   -0.32038    0.33412   [    -1.3929    0.88819 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: PDERS\n",
      "                         : \n",
      "PDERS                    : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_PDERS          : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: PDEFoam\n",
      "                         : \n",
      "PDEFoam                  : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_PDEFoam        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: KNN\n",
      "                         : \n",
      "KNN                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_KNN            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: LD\n",
      "                         : \n",
      "LD                       : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Also filling probability and rarity histograms (on request)...\n",
      "TFHandler_LD             : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: FDA_GA\n",
      "                         : \n",
      "FDA_GA                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_FDA_GA         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: MLPBNN\n",
      "                         : \n",
      "TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]\n",
      "                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]\n",
      "                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]\n",
      "                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]\n",
      "                         : -----------------------------------------------------------\n",
      "MLPBNN                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]\n",
      "                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]\n",
      "                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]\n",
      "                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: DNN_CPU\n",
      "                         : \n",
      "DNN_CPU                  : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]\n",
      "                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]\n",
      "                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]\n",
      "                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]\n",
      "                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]\n",
      "                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]\n",
      "                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: SVM\n",
      "                         : \n",
      "TFHandler_SVM            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]\n",
      "                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]\n",
      "                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]\n",
      "                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]\n",
      "                         : -----------------------------------------------------------\n",
      "SVM                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_SVM            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]\n",
      "                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]\n",
      "                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]\n",
      "                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: BDT\n",
      "                         : \n",
      "BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: RuleFit\n",
      "                         : \n",
      "RuleFit                  : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_RuleFit        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]\n",
      "                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]\n",
      "                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       LD             : 0.921\n",
      "                         : dataset       MLPBNN         : 0.919\n",
      "                         : dataset       DNN_CPU        : 0.919\n",
      "                         : dataset       LikelihoodPCA  : 0.913\n",
      "                         : dataset       CutsD          : 0.908\n",
      "                         : dataset       SVM            : 0.898\n",
      "                         : dataset       RuleFit        : 0.881\n",
      "                         : dataset       BDT            : 0.881\n",
      "                         : dataset       KNN            : 0.838\n",
      "                         : dataset       PDEFoam        : 0.822\n",
      "                         : dataset       PDERS          : 0.797\n",
      "                         : dataset       Cuts           : 0.792\n",
      "                         : dataset       FDA_GA         : 0.784\n",
      "                         : dataset       Likelihood     : 0.760\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              LD             : 0.364 (0.438)       0.781 (0.758)      0.929 (0.920)\n",
      "                         : dataset              MLPBNN         : 0.343 (0.432)       0.777 (0.768)      0.926 (0.920)\n",
      "                         : dataset              DNN_CPU        : 0.369 (0.404)       0.775 (0.751)      0.924 (0.922)\n",
      "                         : dataset              LikelihoodPCA  : 0.288 (0.316)       0.756 (0.729)      0.920 (0.913)\n",
      "                         : dataset              CutsD          : 0.262 (0.449)       0.735 (0.709)      0.914 (0.890)\n",
      "                         : dataset              SVM            : 0.321 (0.332)       0.711 (0.725)      0.894 (0.898)\n",
      "                         : dataset              RuleFit        : 0.075 (0.077)       0.667 (0.718)      0.893 (0.896)\n",
      "                         : dataset              BDT            : 0.275 (0.402)       0.661 (0.731)      0.870 (0.899)\n",
      "                         : dataset              KNN            : 0.195 (0.252)       0.561 (0.642)      0.810 (0.843)\n",
      "                         : dataset              PDEFoam        : 0.173 (0.219)       0.499 (0.541)      0.761 (0.773)\n",
      "                         : dataset              PDERS          : 0.158 (0.171)       0.465 (0.492)      0.750 (0.756)\n",
      "                         : dataset              Cuts           : 0.112 (0.133)       0.444 (0.496)      0.741 (0.758)\n",
      "                         : dataset              FDA_GA         : 0.121 (0.134)       0.435 (0.471)      0.727 (0.746)\n",
      "                         : dataset              Likelihood     : 0.082 (0.096)       0.388 (0.415)      0.690 (0.695)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 10000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 2000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory->EvaluateAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c88b1",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090f498",
   "metadata": {},
   "source": [
    "Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c91bafe8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:19:00.230105Z",
     "iopub.status.busy": "2024-12-13T10:19:00.229740Z",
     "iopub.status.idle": "2024-12-13T10:19:00.459520Z",
     "shell.execute_reply": "2024-12-13T10:19:00.458428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Wrote root file: TMVAC.root\n",
      "==> TMVAClassification is done!\n"
     ]
    }
   ],
   "source": [
    "outputFile->Write();\n",
    "\n",
    "std::cout << \"==> Wrote root file: \" << outputFile->GetName() << std::endl;\n",
    "std::cout << \"==> TMVAClassification is done!\" << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0956868",
   "metadata": {},
   "source": [
    "Launch the GUI for the root macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42aca33b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T10:19:00.463458Z",
     "iopub.status.busy": "2024-12-13T10:19:00.463156Z",
     "iopub.status.idle": "2024-12-13T10:19:00.680378Z",
     "shell.execute_reply": "2024-12-13T10:19:00.679236Z"
    }
   },
   "outputs": [],
   "source": [
    "if (!gROOT->IsBatch()) TMVA::TMVAGui( outfileName );\n",
    "\n",
    "return 0;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
